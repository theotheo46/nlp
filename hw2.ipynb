{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWbZmlzJh8S7"
   },
   "source": [
    "## Домашнее задание 2. Классификация тональности\n",
    "\n",
    "В этом задании мы будем решать задачу классификации тональности отзывов о ресторанах. Задачу классификации тональности текста часто решают для автоматизации анализа обратной связи в случаях, когда пользователи не ставят числовую оценку. Например, так можно проанализировать общее настроение комментариев под постом в социальной сети или под видео на видеохостинговой платформе.\n",
    "\n",
    "В этом задании вам предстоит:\n",
    "\n",
    "1. Немного предобработать данные.\n",
    "2. Обучить несколько моделей для задачи классификации и сравнить их между собой:\n",
    "    1. Наивный Байес\n",
    "    1. TF-IDF\n",
    "    1. Сверточную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ol5O0Y8eh8S9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWwxAkUUz1v2"
   },
   "source": [
    "Начнем с загрузки данных. Мы будем использовать датасет Yelp. Он содержит около 450 тысяч коротких негативных и позитивных отзывов о ресторанах. Это академический датасет, и раньше он часто использовался для тестирования моделей в научных работах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ugJnXzPSz1v3"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('yelp_train.csv')\n",
    "test_data = pd.read_csv('yelp_test.csv')\n",
    "\n",
    "texts_train = train_data.text\n",
    "labels_train = train_data.label\n",
    "texts_test = test_data.text\n",
    "labels_test = test_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JJWXvHcz1v3",
    "outputId": "67d385d1-2f22-4ae8-886f-450f38636ba2"
   },
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzWl1xGkz1v4",
    "outputId": "730f7565-b920-4b6d-b700-f0dfa3173216"
   },
   "outputs": [],
   "source": [
    "texts_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41HPPYqyz1v4"
   },
   "source": [
    "Посмотрим на распределение классов. Для оценки качества можем использовать обычную точность (accuracy), так как классы достаточно сбалансированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "SJKFfWGNh8TA",
    "outputId": "fbffbf35-d5ea-4204-8c33-e1eb408de8e0"
   },
   "outputs": [],
   "source": [
    "labels_train.value_counts().plot(kind='pie', explode=[0, 0.1], figsize=(4, 4), autopct='%1.1f%%')\n",
    "plt.title(\"Positive vs Negative\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD7KaaYMh8TA"
   },
   "source": [
    "## Предобработка данных\n",
    "\n",
    "Каждый датасет требует индивидуального подхода и предобработка данных зависит от задачи, которую мы решаем. Из стандартных практик для задачи классификации можно выделить _приведение к нижнему регистру_, _лемматизацию_ и _удаление пунктуации_. То есть все то, что почти не меняет содержащуюся информацию. Однако для каждой задачи __обязательно__ надо думать, какую информацию точно нельзя удалять. Например, для этой задачи не стоит удалять стоп-слова (not, no, isn't, always и т.д.), потому что они могут быть важны для классификации тональности. Если у вас нет интуиции о том, какая информация может быть полезна, то __лучше сохранить все__.\n",
    "\n",
    "__Задание 1.__\n",
    "Приведите тренировочные и тестовые данные к нижнему регистру, удалите пунктуацию и лемматизуйте. Для проверки запишите обработанный тренировочный корпус в текстовый файл `clean_text_train.txt` в формате обычного текста, в котором тексты отделены переносом строки и сдайте в грейдер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZ4NIXUuh8TB",
    "outputId": "55549b73-05d8-4062-c31c-14bb680f5247"
   },
   "outputs": [],
   "source": [
    "def clean_texts(texts) -> list:\n",
    "    # ваш код здесь\n",
    "    pass\n",
    "\n",
    "clean_texts_train = clean_texts(texts_train)\n",
    "\n",
    "with open('clean_text_train.txt', 'w') as f:\n",
    "    for text in clean_texts_train:\n",
    "        f.write(' '.join(text))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head clean_text_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IktthSCzh8TC"
   },
   "source": [
    "## Метрика\n",
    "\n",
    "Как уже было сказано, для оценки качества будем считать точность. Загрузим эту метрику из `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fBn91oMh8TC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JVjp8DRh8TD"
   },
   "source": [
    "## Наивный Байес\n",
    "\n",
    "Наивный байесовский классификатор считает все слова в тексте независимыми и предсказывает класс по формуле\n",
    "$$\n",
    "\\hat{y} = \\underset{y}{\\text{argmax}} \\, p(y) \\prod_{i=1}^n p(x_i | y)\n",
    "$$\n",
    "или\n",
    "$$\n",
    "\\hat{y} = \\underset{y}{\\text{argmax}} \\, p(y) \\prod_{w \\in V} p(w | y)^{\\text{count}(w)}\n",
    "$$\n",
    "\n",
    "__Задание 2.__ Обучите Наивный Байес на Bag of Words представлениях текстов. В качестве модели возьмите `MultinomialNB` из `sklearn`. Замерьте точность на тестовой выборке. Если вы все сделали правильно, у вас должно получиться не меньше 0.91.   \n",
    "Оформите решение в виде функции `train_nb_model`. Она принимает на вход список текстов (список списков слов) и список их меток и возвращает обученную модель `MultinomialNB` вместе с BoW моделью `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79-iC-D3h8TF"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mggd_O6Sh8TF",
    "outputId": "2911fc49-0d17-425c-c094-d3b4ab0e34bf"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def train_nb_model(texts: List[List[str]], labels: List[int]) -> (MultinomialNB, CountVectorizer):\n",
    "    # ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs9zVu45z1v6"
   },
   "source": [
    "## TF-IDF + Логистическая регрессия\n",
    "\n",
    "Наивный Байес редко работает хорошо, так как он очень чувствителен к редким словам. Гораздо более распространенный и рабочий подход – любой классификатор (логистиченая регрессия, SVM, случайный лес, градиентный бустинг) поверх TF-IDF признаков.\n",
    "\n",
    "__Задание 3.__ Закодируйте тексты с помощью TF-IDF и обучите на этом логистическую регрессию. Помните, что считать TF-IDF нужно только на обучающей выборке. Удалось ли таким подходом обогнать Наивный Байес?   \n",
    "В грейдер сдайте код для функции `train_lr_model`. Структура функции аналогична с функции из предыдущего задания. Возвращайте модель и векторизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od-rFR_9h8TG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia093vyqh8TG",
    "outputId": "ff7b8058-bed5-4e0e-8c92-db445aff2458"
   },
   "outputs": [],
   "source": [
    "def train_lr_model(texts: List[List[str]], labels: List[int]) -> (LogisticRegression, TfidfVectorizer):\n",
    "    # ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDNhPrlLh8TH"
   },
   "source": [
    "## TF-IDF и n-граммы\n",
    "\n",
    "На данный момент мы вообще не учитываем связи между словами, хотя для нашей задачи они точно важны. Например \"хорошо\" в сочетании с \"не\" имеет полностью противоположный смысл, что напрямую влияет на класс. Хотелось бы дать возможность модели получать эту информацию напрямую. Самый популярный на практике способо это сделать – добавить в модель n-граммы слов.\n",
    "\n",
    "__Задание 4.__ Настройте аргумент `ngram_range` в `TfidfVectorizer` так, чтобы модель учитывала n-граммы. Чем больше n, тем больше признаков получится в итоге. Мы советуем ограничиться 3-граммами и удалить редкие слова (параметр `min_df`), чтобы словарь рос не так быстро.   \n",
    "Модифицируйте описанным образом функцию `train_lr_model` и сдайте ее код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr_model(texts: List[List[str]], labels: List[int]) -> (LogisticRegression, TfidfVectorizer):\n",
    "    # ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55ErCJMXh8TI"
   },
   "source": [
    "## Сверточные нейронные сети\n",
    "\n",
    "Настало время для тяжелой артиллерии. На данный момент у вас должен был получиться очень хороший бейзлайн, однако его можно улучшить и дальше, например, применив сверточные модели. Важно заметить, что на многих простых задачах классификации TF-IDF и логрег побить не удается, однако в анализе тональности очень важна контекстная информация, которую можно извлечь сверточной сетью.\n",
    "\n",
    "### Подготовка датасета\n",
    "\n",
    "Для обучения нейронных сетей нам нужно немного переделать датасет. Во-первых, удалим все редкие слова. При обучении TF-IDF для таких слов автоматически ставился низкий вес. Сверточная сеть же учитывает все слова с одним вестом и редкие слова выучивает гораздо хуже, из-за чего качество может упасть.\n",
    "\n",
    "__Задание 5.__ Удалите из тренировочного и тестового корпусов все слова, которые встречаются меньше, чем в 15 текстах. Для проверки запишите очищенный тренировочный корпус в текстовый файл `rare_text_train.txt` в формате обычного текста и сдайте в грейдер.   \n",
    "__Важно:__ список редких слов можно составлять только по обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUTH08w1z1v7",
    "outputId": "2ca58c09-bc8c-4c17-81e6-60daf9e75cec"
   },
   "outputs": [],
   "source": [
    "def remove_rare_words(texts) -> list:\n",
    "    # ваш код здесь\n",
    "    pass\n",
    "\n",
    "rare_texts_train = remove_rare_words(texts_train)\n",
    "\n",
    "with open('rare_text_train.txt', 'w') as f:\n",
    "    for text in rare_texts_train:\n",
    "        f.write(' '.join(text))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxJtivUEh8TI"
   },
   "source": [
    "Нейронная сеть получает на вход индексы слов. Соответственно, нам надо превратить слова в индексы. Удобнее всего для этого использовать `gensim.corpora.dictionary.Dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4LJcD7-h8TI",
    "outputId": "0cd93d13-58b6-43de-88cb-a485c989a7db"
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "dictionary = Dictionary(texts_train)\n",
    "dictionary.add_documents([['PAD', 'UNK']])\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1QZDQePz1v7",
    "outputId": "2a307c45-e8b4-45cd-b9c7-1e1d110b56b5"
   },
   "outputs": [],
   "source": [
    "list(dictionary.token2id.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axKiDYufz1v7"
   },
   "source": [
    "Соберем датасет из пар (текст, класс), чтобы можно было подать его в `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgOdLIT2h8TR"
   },
   "outputs": [],
   "source": [
    "train_dataset = list(zip(texts_train, labels_train))\n",
    "test_dataset = list(zip(texts_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAFiUVAnh8TS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Функция для обработки каждого батча\n",
    "# Добавляем паддинги и превращаем все в тензоры\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    pad_token_id = dictionary.token2id['PAD']\n",
    "    unk_token_id = dictionary.token2id['UNK']\n",
    "    input_ids = [torch.tensor(dictionary.doc2idx(text, unknown_word_index=unk_token_id)) for text in texts]\n",
    "    return (\n",
    "        pad_sequence(input_ids, padding_value=pad_token_id).permute(1, 0).to(torch.long),\n",
    "        torch.tensor(labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBfzhWMAz1v8"
   },
   "source": [
    "Наконец, получаем `DataLoader`, из которого мы будем доставать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gn6_T0D2h8TS"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, collate_fn=collate_fn, shuffle=True, batch_size=128)\n",
    "test_loader = DataLoader(test_dataset, collate_fn=collate_fn, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5N7qiuyz1v8"
   },
   "source": [
    "__Задание 6.__ Допишите сверточную сеть на основе 1d сверток. Число слоев и общую архитектуру выберите на ваш вкус. Однако не стройте сразу слишком большую модель, 400 тысяч параметров без слоя эмбеддингов вам точно должно хватить за глаза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSkTXHLwh8TS"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hid_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hid_dim)\n",
    "\n",
    "        # ваш код здесь\n",
    "\n",
    "        self.fc = nn.Linear(hid_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ваш код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byv0VXCFjRcP"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Upa5xRUrh8TS"
   },
   "outputs": [],
   "source": [
    "model = CNN(vocab_size=len(dictionary), hid_dim=...).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "n_params = sum(torch.numel(p) for p in model.parameters())\n",
    "n_emb_params = sum(torch.numel(p) for p in model.embedding.parameters())\n",
    "print(f\"Число параметров без эмбеддингов: {n_params - n_emb_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3J03R1Mqz1v8"
   },
   "source": [
    "__Задание 7.__ Обучите полученную модель на обработанных данных. Цикл обучения можно взять из семинара, но можно и написать самостоятельно. Советуем для логирования использовать wandb. Примерно 2 эпох должно хватить, чтобы пройти тесты, и 10, чтобы получить качество лучше TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4BxTFEah8TS"
   },
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lw_pg8kz1wH"
   },
   "source": [
    "__ДОПОЛНИТЕЛЬНОЕ ЗАДАНИЕ (НЕ ОЦЕНИВАЕТСЯ)__\n",
    "\n",
    "Сверточная модель хорошо улавливает контекстную информацию для каждого слова. Однако ее проблема заключается в аггрегировании выхода сверток в один вектор. При суммировании важная информация смешивается с бесполезной, почти то же самое происходит и с max-pooling.   \n",
    "Для решения этой проблемы добавим подобие механизма внимания. Вместо обычной аггрегации мы применим линейный слой к выходам последней свертки, который выдаст распределение важности каждого вектора. Применим софтмакс к полученным важностям и сложим все векторы с этими весами. Таким образом модель получит возможность самостоятельно выбирать векторы, которые ей важнее сохранить при аггрегации.\n",
    "\n",
    "\\begin{align}\n",
    "&x \\in \\mathbb{R}^{n\\, \\times\\, d} – \\text{карта признаков (выходы последней свертки)} \\\\\n",
    "&Att = \\text{softmax}(x \\times w + b) \\\\\n",
    "&out = \\sum_{i=1}^{n} x_i \\cdot Att_i\n",
    "\\end{align}\n",
    "\n",
    "где $w \\in \\mathbb{R}^{d}, b \\in \\mathbb{R}$ – обучаемые параметры.\n",
    "\n",
    "__Задание 8.__ Добавьте описанный слой внимания в вашу модель и обучите ее с теми же параметрами и сравните качество. Возможно, придется немного поколдовать со значением learning rate, но в результате точность должна улучшиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2e3el8oh8TS"
   },
   "outputs": [],
   "source": [
    "class AttentionCNN(CNN):\n",
    "    def __init__(self, vocab_size, hid_dim):\n",
    "        super().__init__(vocab_size, hid_dim)\n",
    "\n",
    "        # ваш код здесь\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ваш код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB35jZh0h8TT"
   },
   "outputs": [],
   "source": [
    "model = AttentionСNN(vocab_size=len(dictionary), hid_dim=...).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew0xNoQwnroT"
   },
   "source": [
    "## Резюме\n",
    "\n",
    "В этом задании мы проделали классическую работу NLP-инженера. Обработали данные подходящим для задачи способом, обучили несколько моделей, начиная с самой простой и постепенно усложняя решение. Скорее всего при обучении сверточной модели вы заметили, что ее качество почти всегда не уступает простому решению через TF-IDF. Если бы мы не начали с простого бейзлайна, то не поняли бы, насколько наша сверточная модель хороша и надо ли ее улучшать.    \n",
    "В результате вы должны были получить точность около 97%. Для данной задачи – это максимальный результат, его нельзя улучшить почти никакими более сложными моделями, так как тексты короткие и в каждом из них есть слова-маркеры, отвечающие за стиль. Почти любая модель их неплохо извлекает.   \n",
    "Впрочем, если у вас есть желание, то можно попытаться. :) В таком случае мы советуем начать с анализа текстов, на которых модель ошибается. Может быть они чем-то выделяются?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
