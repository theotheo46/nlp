{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 4\n",
    "Эта демонстрация разбита на 3 ноутбука:\n",
    "\n",
    "1. Свертки и пулинги.\n",
    "2. Даталоадеры.\n",
    "3. **Задача классификации с использованием CNN.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы решим задачу предсказания пола человека по фото.\n",
    "\n",
    "Метрикой качества будет _accuracy_, датасет возьмем IMDB-Wiki.\n",
    "В качестве бейзлайна возьмем FC-сеть, затем улучшим его с помощью сверток.\n",
    "После этого мы возьмем ResNet, зафайнтюним его под нашу задачу и посмотрим на качество.\n",
    "\n",
    "Мы увидим, что сверточные сети действительно улучшают точность предсказания. Также мы посмотрим на fine-tuning: как быстро он обучится и какое качество даст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImdbWikiDataset(Dataset):\n",
    "    def __init__(self, image_size: int = 128):\n",
    "        # Из кодов выше\n",
    "        imdb_dat = loadmat(\"imdb_crop/imdb.mat\")[\"imdb\"][0][0]\n",
    "        imdb_paths = [f\"imdb_crop/{path[0]}\" for path in imdb_dat[2][0]]\n",
    "        imdb_genders = imdb_dat[3][0]\n",
    "        bad_indices = set(np.where(np.isnan(imdb_genders))[0])\n",
    "        imdb_paths = [x for i, x in enumerate(imdb_paths) if i not in bad_indices]\n",
    "        imdb_genders = [\n",
    "            int(x) for i, x in enumerate(imdb_genders) if i not in bad_indices\n",
    "        ]\n",
    "\n",
    "        # Не будем читать картинки при создании датасета, чтобы сберечь ОЗУ.\n",
    "        self.paths = imdb_paths\n",
    "        self.labels = imdb_genders\n",
    "        self.transforms = A.Compose(\n",
    "            [\n",
    "                # Подгонит под размер (128, 128)\n",
    "                A.Resize(image_size, image_size),\n",
    "                # A.HorizontalFlip(p=0.5),\n",
    "                # Пиксели в отрезке [0; 255] - это uint8.\n",
    "                # Переведем в отрезок [0.0; 1.0] - нейросети будет проще.\n",
    "                A.ToFloat(max_value=255),\n",
    "                # Поменяет (H, W, C) -> (C, H, W) и превратит в тензор PyTorch\n",
    "                ToTensorV2(),\n",
    "                # Для обогащения: будем переворачивать\n",
    "            ]\n",
    "        )\n",
    "        assert len(self.paths) == len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, int]:\n",
    "        # Читать будем только одну картинку - и возвращать пару (тензор картинки, ее label)\n",
    "        img_numpy = cv2.imread(self.paths[index])\n",
    "        img_tensor = self.transforms(image=img_numpy)[\"image\"]\n",
    "\n",
    "        label = self.labels[index]\n",
    "        return img_tensor, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация с использованием сверток\n",
    "\n",
    "Попробуем решить задачу классификации пола на таком большом датасете.\n",
    "Какие модели будем использовать:\n",
    "- FC (_бейзлайн_);\n",
    "- одна свертка и нелинейность;\n",
    "- три свертки;\n",
    "- три свертки и batch normalization;\n",
    "- три свертки, batch normalization, dropout; \n",
    "\n",
    "Оптимизировать будем бинарную кросс-энтропию (BCE), в качестве метрики качества выберем accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 0\n",
    "\n",
    "    # Данные\n",
    "    batch_size: int = 64\n",
    "    do_shuffle_train: bool = True\n",
    "    img_size: int = 128\n",
    "    ratio_train_val_test: tuple[float, float, float] = (0.8, 0.1, 0.1)\n",
    "\n",
    "    # Модель\n",
    "    hidden_dim: int = 512\n",
    "    p_dropout: float = 0.3\n",
    "\n",
    "    # Обучение\n",
    "    n_epochs: int = 10\n",
    "    eval_every: int = 2000\n",
    "    lr: float = 1e-5\n",
    "\n",
    "\n",
    "def enable_determinism():\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def fix_seeds(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "\n",
    "\n",
    "config = Config()\n",
    "enable_determinism()\n",
    "fix_seeds(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Готовим заново датасеты\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(config.seed)\n",
    "\n",
    "dataset = ImdbWikiDataset(image_size=config.img_size)\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, lengths=config.ratio_train_val_test, generator=generator\n",
    ")\n",
    "\n",
    "\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "def seed_worker(_):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=config.do_shuffle_train,\n",
    "    generator=generator,\n",
    "    drop_last=True,\n",
    "    # Для скорости будем готовить данные в 4 процессах\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    # Это для воспроизводимости https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "    worker_init_fn=seed_worker,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "# Здесь не будем использовать test_loader и test_dataset. Но обычно работают так:\n",
    "# - на train данных обучают модель;\n",
    "# - на val данных подбирают гиперпараметры;\n",
    "# - на test данных финально оценивают качество модели (после подбора гиперпараметров)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FcModel(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.img_size = config.img_size\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        n_channels = 3\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.img_size * self.img_size * n_channels, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.hidden_dim),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.hidden_dim // 2),\n",
    "            nn.Linear(self.hidden_dim // 2, self.hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.hidden_dim // 4),\n",
    "            nn.Linear(self.hidden_dim // 4, 1),\n",
    "            # Будем предсказывать логиты вероятностей\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Схлопнем (N, C, H, W) -> (N, C * H * W)\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        # И прогоним через линейные слои\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = FcModel(config)\n",
    "x, y = next(iter(train_loader))\n",
    "print(x.shape)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пойдем учиться.\n",
    "# В качестве ошибки возьмем BCE\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import wandb\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "def calc_accuracy(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "    count_correct, count_total = 0, 0\n",
    "    model.eval()\n",
    "    for img_batch, true_labels in loader:\n",
    "        img_batch = img_batch.to(device)\n",
    "        true_labels = true_labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred_val = model(img_batch).squeeze()\n",
    "        # Будем предсказывать самый вероятный класс (т.е. порог 0.5 вероятности).\n",
    "        # Тогда p > 0.5 будет на положительных логитах, а p < 0.5 - на отрицательных\n",
    "        pred_labels = pred_val >= 0\n",
    "        count_correct += (pred_labels == true_labels).sum().item()\n",
    "        count_total += len(true_labels)\n",
    "    model.train()\n",
    "    return count_correct / count_total\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "    config: Config,\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    params_subset: list | None = None,\n",
    "):\n",
    "    if params_subset is None:\n",
    "        params_subset = model.parameters()\n",
    "    optimizer = Adam(params_subset, lr=config.lr)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(config.n_epochs):\n",
    "        print(f\"Epoch #{epoch + 1}/#{config.n_epochs}\")\n",
    "        for i, (img_batch, true_labels) in enumerate(tqdm.tqdm(train_loader)):\n",
    "            step = epoch * len(train_loader) + i\n",
    "            img_batch, true_labels = img_batch.to(device), true_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_labels = model(img_batch).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(pred_labels, true_labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            wandb.log({\"loss\": loss.cpu().item()}, step=step)\n",
    "            if (i + 1) % config.eval_every == 0:\n",
    "                # Подсчитаем accuracy на всем валидационном датасете\n",
    "                wandb.log(\n",
    "                    {\"accuracy\": calc_accuracy(model, val_loader, device)}, step=step\n",
    "                )\n",
    "        # В конце эпохи тоже напечатаем accuracy на val-датасете\n",
    "        wandb.log({\"accuracy\": calc_accuracy(model, val_loader, device)}, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Apple Silicon\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtheotheo46\u001b[0m (\u001b[33mtheotheo46-trs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/theo/karpov/nlp/wandb/run-20250204_152417-y1wzm6yt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/theotheo46-trs/lesson-4/runs/y1wzm6yt' target=\"_blank\">simple-fc</a></strong> to <a href='https://wandb.ai/theotheo46-trs/lesson-4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/theotheo46-trs/lesson-4' target=\"_blank\">https://wandb.ai/theotheo46-trs/lesson-4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/theotheo46-trs/lesson-4/runs/y1wzm6yt' target=\"_blank\">https://wandb.ai/theotheo46-trs/lesson-4/runs/y1wzm6yt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1/#10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5653 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'ImdbWikiDataset' on <module '__main__' (built-in)>\n",
      "  0%|          | 0/5653 [01:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple-fc\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(config, model, train_loader, val_loader, device, params_subset)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (img_batch, true_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_loader)):\n\u001b[1;32m     42\u001b[0m         step \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m+\u001b[39m i\n\u001b[1;32m     43\u001b[0m         img_batch, true_labels \u001b[38;5;241m=\u001b[39m img_batch\u001b[38;5;241m.\u001b[39mto(device), true_labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/karpov/nlp/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/karpov/nlp/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/karpov/nlp/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/karpov/nlp/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"lesson-4\", name=\"simple-fc\", config=config.__dict__)\n",
    "train_loop(config, model, train_loader, val_loader=val_loader, device=device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy 69% - негусто. А какое качество дало бы константное предсказание?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(dataset.labels)\n",
    "c[1] / (c[1] + c[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бейзлайн лучше, чем константное предсказние, но несильно.\n",
    "\n",
    "Давайте попробуем улучшить accuracy через сверточные сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModelBase(nn.Module):\n",
    "    def build_model(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def explain_output(self, x: torch.Tensor):\n",
    "        # Печатает размеры тензора на выходе каждого слоя\n",
    "        print(\"## Модель ##\")\n",
    "        print(model)\n",
    "        print(\"## Размерности\")\n",
    "        print(\"Пришел x:\", x.shape)\n",
    "        current = x\n",
    "        for one_layer in self.net:\n",
    "            print(\"#######\")\n",
    "            print(\"Слой:\".ljust(8), one_layer)\n",
    "            print(\"До:\".ljust(8), current.shape)\n",
    "            current = one_layer(current)\n",
    "            print(\"После:\".ljust(8), current.shape)\n",
    "        print(\"## После всей модели\")\n",
    "        print(self(x).shape)\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # Нам хватит поменьше размерности внутри\n",
    "        self.hidden_dim = 64\n",
    "        self.n_channels = 3\n",
    "        self.net = self.build_model()\n",
    "        self.head = nn.Linear(in_features=self.hidden_dim, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x).squeeze()\n",
    "        x = self.head(x).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCnn(CnnModelBase):\n",
    "    def build_model(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.n_channels, out_channels=self.hidden_dim, kernel_size=3\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=self.config.img_size - 3 + 1),\n",
    "        )\n",
    "\n",
    "\n",
    "model = SimpleCnn(config)\n",
    "x, y = next(iter(train_loader))\n",
    "model.explain_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"lesson-4\", name=\"1-conv\", config=config.__dict__)\n",
    "train_loop(config, model, train_loader, val_loader, device=device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn3Layers(CnnModelBase):\n",
    "    def build_model(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.n_channels, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_dim, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_dim, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=28),\n",
    "        )\n",
    "\n",
    "\n",
    "model = Cnn3Layers(config)\n",
    "x, _ = next(iter(train_loader))\n",
    "model.explain_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"lesson-4\", name=\"3-conv\", config=config.__dict__)\n",
    "train_loop(config, model, train_loader, val_loader, device=device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn3LayersBn(CnnModelBase):\n",
    "    def build_model(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.n_channels, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            # >>>>>\n",
    "            nn.BatchNorm2d(self.hidden_dim),\n",
    "            # <<<<<\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_dim, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            # >>>>>\n",
    "            nn.BatchNorm2d(self.hidden_dim),\n",
    "            # <<<<<\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_dim, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            # >>>>>\n",
    "            nn.BatchNorm2d(self.hidden_dim),\n",
    "            # <<<<<\n",
    "            nn.MaxPool2d(kernel_size=28),\n",
    "        )\n",
    "\n",
    "\n",
    "model = Cnn3LayersBn(config)\n",
    "x, _ = next(iter(train_loader))\n",
    "model.explain_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"lesson-4\", name=\"3-conv-bn\", config=config.__dict__)\n",
    "train_loop(config, model, train_loader, val_loader, device=device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn3LayersBnDropout(CnnModelBase):\n",
    "    def build_model(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.n_channels, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(self.hidden_dim),\n",
    "            # >>>>>\n",
    "            nn.Dropout(p=self.config.p_dropout),\n",
    "            # <<<<<\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_dim, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(self.hidden_dim),\n",
    "            # >>>>>\n",
    "            nn.Dropout(p=self.config.p_dropout),\n",
    "            # <<<<<\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.hidden_dim, kernel_size=3, out_channels=self.hidden_dim\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(self.hidden_dim),\n",
    "            # >>>>>\n",
    "            nn.Dropout(p=self.config.p_dropout),\n",
    "            # <<<<<\n",
    "            nn.MaxPool2d(kernel_size=28),\n",
    "        )\n",
    "\n",
    "\n",
    "model = Cnn3LayersBn(config)\n",
    "x, _ = next(iter(train_loader))\n",
    "model.explain_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"lesson-4\", name=\"3-conv-bn-dropout\", config=config.__dict__)\n",
    "train_loop(config, model, train_loader, val_loader, device=device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: сверточные сети действительно помогли выбить большее качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning готовой модели\n",
    "Возьмем обученный ResNet и попробуем адаптировать его мощь под нашу задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "\n",
    "\n",
    "def make_resnet():\n",
    "    \"\"\"Сделать модель resnet для fine-tuning.\n",
    "\n",
    "    1. Скачивает готовый обученный ResNet.\n",
    "    2. Заменяет последний слой в нем на Linear(..., 1).\n",
    "    3. Инициализирует веса этому слою.\n",
    "    \"\"\"\n",
    "    fix_seeds(config.seed)\n",
    "    base_model = resnet34()\n",
    "    base_model.fc = nn.Linear(base_model.fc.in_features, 1)\n",
    "    torch.nn.init.xavier_uniform_(base_model.fc.weight)\n",
    "    return base_model\n",
    "\n",
    "\n",
    "resnet = make_resnet()\n",
    "resnet(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_params = [v for k, v in resnet.named_parameters() if k in {'fc.weight', 'fc.bias'}]\n",
    "fc_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"lesson-4\", name=\"resnet-finetune\", config=config.__dict__)\n",
    "train_loop(\n",
    "    config, resnet, train_loader, val_loader, device=device, params_subset=fc_params\n",
    ")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще, мы могли зафайнтюнить не только ResNet, но и любую сеть из рассмотренных на лекции!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG\n",
    "from torchvision.models import vgg11\n",
    "\n",
    "vgg = vgg11()\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете самостоятельно попробовать поменять ResNet на любую из изученных в лекции архитектур - и сравнить качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Резюме\n",
    "\n",
    "1. Научились работать с датасетами/даталоадерами.\n",
    "2. Посмотрели на качество FC и CNN в классификации картинок - увидели, что CNN выбивает большее качество.\n",
    "3. Попробовали сделать fine-tuning ResNet под нашу задачу."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
