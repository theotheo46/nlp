{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Знакомство с инструментом PyTorch\n",
    "\n",
    "## План\n",
    "В этом ноутбуке посмотрим на базовые возможности PyTorch:\n",
    "\n",
    "0. Подсказки при работе с Jupyter Notebook.\n",
    "1. Как создать тензор.\n",
    "2. Операции с тензором.\n",
    "3. Функции над тензором.\n",
    "4. Градиенты в PyTorch.\n",
    "5. Функции потерь.\n",
    "6. Слои нейросети.\n",
    "8. PyTorch и видеокарта.\n",
    "\n",
    "## Почему именно PyTorch?\n",
    "Этот инструмент стал популярен в мире DL.\n",
    "Причин много, но из самых интересных стоит выделить три:\n",
    "1. PyTorch имеет numpy-подобный интерфейс, поэтому на него легко перейти после numpy.\n",
    "2. PyTorch умеет автоматически считать градиенты всех вычислений, независимо от количества операций.\n",
    "Можно учить модели произвольного размера.\n",
    "3. В PyTorch уже реализовано много часто используемых в DL операций и слоев нейросетей.\n",
    "4. Все вычисления на PyTorch без головной боли можно перенести на GPU и получить прирост x100 в скорости.\n",
    "\n",
    "## PyTorch: начало\n",
    "\n",
    "Если вы используете Google Colab или Kaggle Notebooks,\n",
    "то у вас уже установлен `pytorch`.\n",
    "На 2024-02-10 они оба используют версии 2.1.\n",
    "\n",
    "<details>\n",
    "<summary>**Если используете личный ноутбук или сервер**</summary>\n",
    "\n",
    "Ваш ноутбук или сервер должны иметь видеокарту, и `pytorch` должен \"увидеть\" ее.\n",
    "\n",
    "Сначала устанавливаем пакет `pytorch`.\n",
    "Лучше всего это делать в виртуальном окружении (можно и в anaconda).\n",
    "Выполняем в терминале команду:\n",
    "\n",
    "```bash\n",
    "pip install torch\n",
    "```\n",
    "\n",
    "Затем открываем интерпретатор Python и выполняем:\n",
    "```python\n",
    "import torch\n",
    "torch.cuda.is_avaliable()\n",
    "# Должно выдать True\n",
    "```\n",
    "\n",
    "Если выдало `True`, то `pytorch` увидел вашу видеокарту и может работать с ней.\n",
    "Если выдало `False` или ошибку, то рекомендуем прочитать [официальную инструкцию](https://pytorch.org/get-started/locally/) по установке - в ней описано, как установить `pytorch` так, чтобы он \"видел\" видеокарту.\n",
    "Если же и инструкция не помогла, то советуем работать в Google Colab или Kaggle Notebooks.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсказки при работе с Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb86cd33490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sq  # Нажмите <Tab>, чтобы увидеть подсказки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/__init__.py\n",
      "\u001b[0;31mType:\u001b[0m           _TensorMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     SparseSemiStructuredTensor, Parameter, UninitializedBuffer, MaskedTensor, FakeTensor, FunctionalTensor"
     ]
    }
   ],
   "source": [
    "# В Jupyter Notebook можно распечатать документацию к классу или функции\n",
    "# Для этого нужно написать в конце \"?\"\n",
    "torch.Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: D400,D402\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Measures the element-wise mean squared error.\u001b[0m\n",
      "\u001b[0;34m    See :class:`~torch.nn.MSELoss` for details.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"Using a target size ({target.size()}) that is different to the input size ({input.size()}). \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"This will likely lead to incorrect results due to broadcasting. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/functional.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "# Можно также распечатать весь исходный код, дописав в конец \"??\"\n",
    "torch.nn.functional.mse_loss??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тензор: великий и ужасный\n",
    "\n",
    "Напомним: тензор — это всего лишь набор чисел, расфасованных по осям.\n",
    "О тензоре можно думать как о матрице — вот только если матрица была двумерна, то тензор может иметь три и более размерности.\n",
    "\n",
    "Тензор с размерностью 1 — это вектор, список чисел.\n",
    "\n",
    "Тензор с размерностью 2 — это матрица, то есть список списков чисел.\n",
    "\n",
    "Тензор с размерностью 3 и больше — это тензор, то есть список списков списков (и т.д.) чисел.\n",
    "\n",
    "\n",
    "![meme](./meme.png)\n",
    "\n",
    "#### Как создать тензор\n",
    "Научимся создавать:\n",
    "1. Тензор с непредсказуемыми данными (самый простой вариант).\n",
    "2. Тензор из нулей.\n",
    "3. Тензор, заполненный одним и тем же числом.\n",
    "4. Тензор со значениями из нормального распределения.\n",
    "\n",
    "Также познакомимся с in-place операциями и тем, как с ними не запутаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 1.1632e+33, 2.6302e+20, 6.1949e-04],\n",
       "         [6.4805e-10, 6.3011e-10, 1.6501e-07, 6.7214e-04],\n",
       "         [6.7739e-10, 4.1020e-08, 6.4097e-10, 1.4580e-19]],\n",
       "\n",
       "        [[1.1495e+24, 3.0956e-18, 2.9907e+21, 3.2944e-09],\n",
       "         [1.0073e-11, 1.0665e-08, 6.7377e-10, 6.7003e-10],\n",
       "         [6.3075e-10, 6.7016e-10, 8.2188e+20, 2.3878e-18]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Есть много способов создать тензор в torch.\n",
    "Посмотрим на некоторые из них.\n",
    "\"\"\"\n",
    "\n",
    "# Самый простой — запросить тензор определенной размерности\n",
    "\n",
    "t = torch.Tensor(2, 3, 4)\n",
    "# Будет заполнен произвольными непредсказуемыми данными\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Можно спросить, какой размер. Помним, что было (2, 3, 4)\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Есть .shape — работает аналогично\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape можно удобно сравнивать с tuple — пригодится в тестах\n",
    "assert t.shape == (2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В torch много функций для самых \"ходовых\" тензоров.\n",
    "# Например, создать тензор из нулей\n",
    "# Сделаем матрицу (5, 3), заполненную нулями\n",
    "torch.zeros((5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тензор (2, 3, 4), все числа равны 1.\n",
    "# Обратите внимание на точку после 1. — это значит, что тип float\n",
    "t = torch.ones((2, 3, 4))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# А если точнее — float32.\n",
    "# На лекции мы знакомились с fp16, fp32 — это оно и есть.\n",
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7000, 2.7000, 2.7000, 2.7000],\n",
       "         [2.7000, 2.7000, 2.7000, 2.7000]],\n",
       "\n",
       "        [[2.7000, 2.7000, 2.7000, 2.7000],\n",
       "         [2.7000, 2.7000, 2.7000, 2.7000]],\n",
       "\n",
       "        [[2.7000, 2.7000, 2.7000, 2.7000],\n",
       "         [2.7000, 2.7000, 2.7000, 2.7000]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# аналогично можно заполнить любыми числами:\n",
    "2.7 * torch.ones((3, 2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на квадратные скобки.\n",
    "По ним видно, что тензор как будто состоит из двух матриц 3x4, соединенных вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.9269,  1.4873,  0.9007, -2.1055],\n",
       "          [ 0.6784, -1.2345, -0.0431, -1.6047]],\n",
       "\n",
       "         [[-0.7521,  1.6487, -0.3925, -1.4036],\n",
       "          [-0.7279, -0.5594, -0.7688,  0.7624]],\n",
       "\n",
       "         [[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
       "          [-0.7581,  1.0783,  0.8008,  1.6806]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2791,  1.2964,  0.6105,  1.3347],\n",
       "          [-0.2316,  0.0418, -0.2516,  0.8599]],\n",
       "\n",
       "         [[-1.3847, -0.8712, -0.2234,  1.7174],\n",
       "          [ 0.3189, -0.4245,  0.3057, -0.7746]],\n",
       "\n",
       "         [[-1.5576,  0.9956, -0.8798, -0.6011],\n",
       "          [-1.2742,  2.1228, -1.2347, -0.4879]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тензор (2, 3, 2, 4), каждый элемент взят из стандартного нормального распределения\n",
    "torch.randn((2, 3, 2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### in-place операции\n",
    "Все рассмотренные выше операции создают **новый** тензор.\n",
    "Но иногда хочется не создавать новый, а менять существующий.\n",
    "\n",
    "Для этого есть т.н. \"in-place\" (\"на месте\") операции — они меняют тот тензор,\n",
    "над которым применяются, и не создают никаких других тензоров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим тензор из единиц\n",
    "t = torch.ones((2, 3))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# И занулим его. Обратите внимание на нижнее подчеркивание.\n",
    "t.zero_()\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В torch все in-place операции строятся как обычные с нижним подчеркиванием (`_`) в конце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[12648521.,  3275686.,    84453.],\n",
      "        [ 5147423.,  1954303., 15271690.]])\n"
     ]
    }
   ],
   "source": [
    "print(t)\n",
    "t.random_()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place операции позволяют сэкономить память, т.к. создаем в два раза меньше тензоров.\n",
    "У этого есть обратная сторона: если мы передаем тензор в функцию, то функция может\n",
    "этот тензор \"испортить\", поменяв его in-place.\n",
    "\n",
    "Посмотрим на примере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_tensor до функции:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Рандомный тензор того же размера:\n",
      "tensor([[1., 4., 0.],\n",
      "        [4., 3., 3.]])\n",
      "zero_tensor после функции:\n",
      "tensor([[1., 4., 0.],\n",
      "        [4., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "def random_like(a: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Создать случайный тензор того же размера, что и `a`.\"\"\"\n",
    "    # перезатираем `a` - это не очень хорошо\n",
    "    return a.random_(0, 5)\n",
    "\n",
    "\n",
    "zero_tensor = torch.zeros((2, 3))\n",
    "print(\"zero_tensor до функции:\")\n",
    "print(zero_tensor)\n",
    "\n",
    "random_tensor = random_like(zero_tensor)\n",
    "print(\"Рандомный тензор того же размера:\")\n",
    "print(random_tensor)\n",
    "\n",
    "print(\"zero_tensor после функции:\")\n",
    "print(zero_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_tensor до функции:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Рандомный тензор того же размера:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 0., 1.]])\n",
      "zero_tensor после функции:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# без перезатирания\n",
    "def random_like(a: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.randint(0, 5, a.shape, dtype=torch.float32)\n",
    "    # еще можно одной строкой\n",
    "    # return torch.randint_like(a, 0, 5)\n",
    "    # у многих функций есть _like аналоги: zero_like, ones_like\n",
    "\n",
    "\n",
    "zero_tensor = torch.zeros((2, 3))\n",
    "print(\"zero_tensor до функции:\")\n",
    "print(zero_tensor)\n",
    "\n",
    "random_tensor = random_like(zero_tensor)\n",
    "print(\"Рандомный тензор того же размера:\")\n",
    "print(random_tensor)\n",
    "\n",
    "print(\"zero_tensor после функции:\")\n",
    "print(zero_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Операции с тензором\n",
    "Тензор создали, что же с ним можно делать дальше?\n",
    "Много чего. Мы рассмотрим несколько типов операций:\n",
    "1. Бинарные — как два тензора могут взаимодействовать.\n",
    "2. Индексирование — как нарезать тензор на куски.\n",
    "3. Продвинутое создание и индексирование — закрепим знания.\n",
    "\n",
    "Первая причина популярности PyTorch: numpy-подобный интерфейс, к которому быстро привыкаешь.\n",
    "Посмотрим, что нам предлагает этот инструмент.\n",
    "##### Бинарные операции\n",
    "Тензоры в PyTorch умеют делать те же операции, что и в NumPy: сложение, умножение, возведение в степень и т.д.\n",
    "Посмотрим на некоторые из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [5., 5., 5.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тензоры одинаковой размерности можно сложить\n",
    "2 * torch.ones((2, 3)) + 3 * torch.ones((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[3., 2., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [2., 3., 2.]])\n",
      "tensor([[3., 0., 0.],\n",
      "        [0., 3., 0.],\n",
      "        [0., 0., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Можно умножать поэлементно\n",
    "a = torch.eye(3)\n",
    "print(a)\n",
    "b = torch.randint_like(a, 2, 4)\n",
    "print(b)\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 5]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[2, 4],\n",
      "        [4, 2]])\n",
      "tensor([[26, 22]])\n"
     ]
    }
   ],
   "source": [
    "# Можно умножить матричным умножением\n",
    "# Обратите внимание на torch.tensor с маленькой буквы — так можно создавать тензор из списка.\n",
    "# каждая вложенность списка — это новая размерность тензора.\n",
    "a = torch.tensor([[3, 5]])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "b = torch.tensor(\n",
    "    [\n",
    "        [2, 4],\n",
    "        [4, 2],\n",
    "    ]\n",
    ")\n",
    "print(b)\n",
    "\"\"\"\n",
    "         2 | 4\n",
    "[3, 5] *   |    = [3*2 + 5*4, 3*4 + 5*2]\n",
    "         4 | 2\n",
    "\"\"\"\n",
    "# оператор @\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39)\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "# Оператор @ также делает скалярное умножение векторов.\n",
    "# Результат тоже будет тензором - нуль-мерным тензором.\n",
    "# Чтобы превратить его в число, используется .item()\n",
    "p = torch.tensor([3, 4]) @ torch.tensor([5, 6])\n",
    "print(p)\n",
    "print(p.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Индексирования\n",
    "Индексирование в PyTorch работает так же, как в NumPy — те же квадратные скобки, те же `:`.\n",
    "Посмотрим на примеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7]])\n",
      "tensor([4, 5])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "    [\n",
    "        [2, 3],\n",
    "        [4, 5],\n",
    "        [6, 7],\n",
    "    ]\n",
    ")\n",
    "print(a)\n",
    "# Взять строку с индексом 1 (нумерация идет с нуля)\n",
    "print(a[1])\n",
    "# Взять строку с индексом 1, а в ней - то, что по индексу 0\n",
    "print(a[1, 0])\n",
    "# Удобнее думать так:\n",
    "# - была размерность (3, 2), берем по индексу 1 вдоль первой оси\n",
    "# - остается размерность (2,), берем по индексу 0 вдоль первой оси\n",
    "# - остается одно число - это 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Можно присваивать через те же [].\n",
    "# Чтобы сказать \"все значения\", используем :\n",
    "a = torch.ones((3, 5, 4, 2))\n",
    "a[:, 3, :, 1] = 2\n",
    "print(a[:, 3, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 2., 2., 0.],\n",
      "        [0., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Можно забирать отрезок из тензора.\n",
    "# Левый конец входит, правый не входит.\n",
    "a = torch.zeros((3, 5))\n",
    "print(a)\n",
    "a[0:2, 2:4] = 2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Продвинутое создание и индексирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6, 8])\n",
      "tensor([2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([10,  8,  6,  4,  2,  0, -2])\n"
     ]
    }
   ],
   "source": [
    "# Тензор с числами в диапазоне.\n",
    "# Левая граница входит, правая не входит.\n",
    "a = torch.arange(2, 9, 2)\n",
    "print(a)\n",
    "a = torch.arange(2, 9)\n",
    "print(a)\n",
    "a = torch.arange(10, -4, -2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В DL часто нужно состыковать размерности на стыке слоев нейросети.\n",
    "Для этого приходится добавлять размерность тензору, либо же его \"повернуть на бок\".\n",
    "\n",
    "Посмотрим, как это делается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0],\n",
       "        [ 3,  2],\n",
       "        [ 6,  4],\n",
       "        [ 9,  6],\n",
       "        [12,  8]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(5)\n",
    "# None в индексировании добавляет ось\n",
    "# -1 в reshape говорит \"сам угадай, сколько по оси элементов\"\n",
    "a[:, None] @ torch.tensor([3, 2]).reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10,  15],\n",
      "        [ 38,  43],\n",
      "        [112, 117]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(5 * 5 * 5).reshape((5, 5, 5))\n",
    "# При индексировании можно явно указать, какие элементы из какого слоя хотим.\n",
    "# Учтите, что \"дырок\" в результате быть не должно\n",
    "print(a[[0, 1, 4], 2:4, [0, 3, 2]])\n",
    "# Не сработает, т.к. в последней оси взяли 2 элемента, а в остальных 3\n",
    "# print(a[[0, 1, 4], 2:4, [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 9, 10, 11],\n",
      "         [18, 19, 20]],\n",
      "\n",
      "        [[ 3,  4,  5],\n",
      "         [12, 13, 14],\n",
      "         [21, 22, 23]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [15, 16, 17],\n",
      "         [24, 25, 26]]])\n"
     ]
    }
   ],
   "source": [
    "from torch.testing import assert_close\n",
    "\n",
    "# Матрицу можно транспонировать\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "print(a)\n",
    "print(a.T)\n",
    "# А если это тензор, то при транспонировании лучше указать две оси\n",
    "a = torch.arange(27).reshape((3, 3, 3))\n",
    "print(a)\n",
    "print(a.transpose(0, 1))\n",
    "\n",
    "# a.transpose(0, 1) - это то же самое, что\n",
    "result = torch.zeros_like(a)\n",
    "for i in range(a.shape[2]):\n",
    "    result[:, :, i] = a[:, :, i].T\n",
    "# assert_close проверяет тензоры на равенство.\n",
    "assert_close(result, a.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функции над тензором\n",
    "Большинство функций, которые есть в NumPy над матрицами,\n",
    "есть и в PyTorch над тензорами.\n",
    "Рассмотрим самые популярные из этих функций:\n",
    "- сложение, умножение, вычитание, деление;\n",
    "- матричное умножение;\n",
    "- обращение тензора;\n",
    "\n",
    "Также разберем нетривиальные моменты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поэлементное умножение:\n",
      "tensor([[ 0,  5],\n",
      "        [12, 21]])\n",
      "То же самое, что '*':\n",
      "tensor([[ 0,  5],\n",
      "        [12, 21]])\n",
      "То же самое, что \"+\", есть inplace-версия a.add_(b):\n",
      "tensor([[ 4,  6],\n",
      "        [ 8, 10]])\n",
      "Возвести в квадрат поэлементно:\n",
      "tensor([[0, 1],\n",
      "        [4, 9]])\n",
      "Обратите внимание: в математической литературе A^2 - это не поэлементно\n",
      "В матем. литературе обычно под A^2 подразумевают следующее:\n",
      "tensor([[ 2,  3],\n",
      "        [ 6, 11]])\n",
      "В частности, обратную матрицу надо считать вот так:\n",
      "tensor([[-1.5000,  0.5000],\n",
      "        [ 1.0000,  0.0000]])\n",
      "Но вот a**(-1) лишь каждый элемент обратит:\n",
      "tensor([[   inf, 1.0000],\n",
      "        [0.5000, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "# Тензоры можно возводить в степень, умножать друг на друга.\n",
    "# Это будет поэлементно!\n",
    "# Вообще, большинство арифметических операций в pytorch выполняются поэлементно.\n",
    "# Это +, -, *, /\n",
    "a = torch.arange(4).reshape((2, 2))\n",
    "b = torch.arange(4, 8).reshape((2, 2))\n",
    "print(\"Поэлементное умножение:\")\n",
    "print(a * b)\n",
    "print(\"То же самое, что '*':\")\n",
    "print(a.mul(b))\n",
    "print('То же самое, что \"+\", есть inplace-версия a.add_(b):')\n",
    "print(a.add(b))\n",
    "print(\"Возвести в квадрат поэлементно:\")\n",
    "print(a**2)\n",
    "print(\"Обратите внимание: в математической литературе A^2 - это не поэлементно\")\n",
    "print(\"В матем. литературе обычно под A^2 подразумевают следующее:\")\n",
    "print(a @ a)\n",
    "print(\"В частности, обратную матрицу надо считать вот так:\")\n",
    "print(a.float().inverse())  # приводим к float, т.к. inverse работает только с ним\n",
    "print(\"Но вот a**(-1) лишь каждый элемент обратит:\")\n",
    "print(a.float() ** (-1))  # pytorch не дает обращать integer элементы тензора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиенты в PyTorch\n",
    "Вторая причина популярности PyTorch: удобная работа с производными операций.\n",
    "\n",
    "PyTorch умеет считать градиенты автоматически.\n",
    "Вы делаете любое вычисление, например:\n",
    "```python\n",
    "result = my_matrix ** 2\n",
    "# затем\n",
    "result.backward()\n",
    "```\n",
    "Более подробная [документация](https://pytorch.org/docs/stable/notes/autograd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [2., 2.]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[ 8.],\n",
      "        [16.]], dtype=torch.float64, grad_fn=<MmBackward0>)\n",
      "tensor([[5., 3.],\n",
      "        [5., 3.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# requires_grad=True означает, что мы хотим считать градиент по всем элементам тензора\n",
    "w = torch.tensor([[1, 1], [2, 2]], dtype=float, requires_grad=True)\n",
    "x = torch.tensor([[5], [3]], dtype=float)\n",
    "print(w)\n",
    "final_answer = w @ x\n",
    "print(final_answer)\n",
    "one_scalar = final_answer.sum()\n",
    "one_scalar.backward()\n",
    "print(w.grad)\n",
    "# градиент можно брать только от скаляров, следующая строка не сработает:\n",
    "# final_answer.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь вручную считаем:\n",
    "$$\n",
    "    \\begin{bmatrix}\n",
    "        w_{11} & w_{12} \\\\\n",
    "        w_{21} & w_{22}\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        x_1 \\\\\n",
    "        x_2\n",
    "    \\end{bmatrix}\n",
    "    = \\begin{bmatrix}\n",
    "        w_{11} x_1 + w_{12} x_2 \\\\\n",
    "        w_{21} x_1 + w_{22} x_2\n",
    "    \\end{bmatrix}\n",
    "    \\xrightarrow{\\sum}\n",
    "    w_{11} x_1 + w_{12} x_2 + w_{21} x_1 + w_{22} x_2\n",
    "$$\n",
    "отсюда видим, что\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{11}} = x_1; \\quad \n",
    "\\frac{\\partial L}{\\partial w_{12}} = x_2; \\quad \n",
    "\\frac{\\partial L}{\\partial w_{21}} = x_1; \\quad \n",
    "\\frac{\\partial L}{\\partial w_{22}} = x_2; \\quad \n",
    "$$\n",
    "Смотрим на числа выше и убеждаемся, что градиент был подсчитан верно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "# Градиент не будет работать без requires_grad=True\n",
    "a = torch.tensor([1.0, 2.0])\n",
    "try:\n",
    "    torch.sum(a).backward()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "tensor([2.4000, 2.4000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73001/3222167747.py:10: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(b.grad)\n"
     ]
    }
   ],
   "source": [
    "# Чтобы суметь подсчитать градиент,\n",
    "# pytorch сохраняет все промежуточные результаты.\n",
    "# Иногда не нужно считать градиент (даже если requires_grad=True)\n",
    "# В таком случае можно попросить не хранить эти промежуточные результаты.\n",
    "# Это экономит память.\n",
    "a = torch.tensor([1.0, 0.2], requires_grad=True)\n",
    "b = a.sum()\n",
    "c = b **2\n",
    "c.backward()\n",
    "print(b.grad)\n",
    "print()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    b = a.sum()\n",
    "# уже не сработает - градиента не было\n",
    "try:\n",
    "    b.backward()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([ 6., 16.])\n",
      "tensor([11., 24.])\n"
     ]
    }
   ],
   "source": [
    "# Если тензор участвует в нескольких вычислениях, то вызов .backwards() сложит градиенты\n",
    "w = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "x = torch.tensor([3.0, 4.0])\n",
    "# Производная loss_1 даст 2w*x = [6, 16]\n",
    "loss_1 = torch.sum(w**2 * x)\n",
    "# Производная loss_2 даст 2w + x = [2 + 3, 4 + 4] = [5, 8]\n",
    "loss_2 = torch.sum(w**2 + w * x + 2)\n",
    "print(w.grad)\n",
    "loss_1.backward()\n",
    "print(w.grad)\n",
    "loss_2.backward()\n",
    "# Две производные сложились: [6, 16] + [5, 8] = [11, 24]\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции потерь\n",
    "В обычном ML было много функций потерь: MSE, MAE, MAPE и так далее.\n",
    "Они есть и pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n",
      "tensor(3.5000)\n",
      "tensor(7.)\n",
      "Градиент (y_true - w @ x)^2:\n",
      "tensor([-4., -4.])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# (5 - 2)^2 = 9\n",
    "loss = F.mse_loss(torch.tensor([2.0]), torch.tensor([5.0]))\n",
    "print(loss)\n",
    "# mean(|2 - 5| + |4 - 0|) = mean(3, 4) = 3.5\n",
    "loss = F.l1_loss(torch.tensor([2.0, 4.0]), torch.tensor([5.0, 0.0]))\n",
    "print(loss)\n",
    "# можно не усреднять, а суммировать\n",
    "loss = F.l1_loss(torch.tensor([2.0, 4.0]), torch.tensor([5.0, 0.0]), reduction=\"sum\")\n",
    "print(loss)\n",
    "\n",
    "# От них можно так же брать градиент!\n",
    "w = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "x = torch.tensor([1.0, 1.0])\n",
    "y_true = torch.tensor(5.0)\n",
    "y_pred = w @ x\n",
    "loss = F.mse_loss(y_pred, y_true)\n",
    "loss.backward()\n",
    "print(\"Градиент (y_true - w @ x)^2:\")\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Слои нейросети\n",
    "На лекции мы узнали, что нейросети строятся из слоев.\n",
    "Есть ли слои в pytorch?\n",
    "\n",
    "Да, они есть — их много готовых.\n",
    "Это третья причина популярности PyTorch: многие слои из мира Deep Learning уже реализованы и готовы к использованию.\n",
    "\n",
    "В этом ноутбуке мы рассмотрим полносвязный слой, с остальными будем знакомиться в следующих уроках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7425],\n",
      "        [-0.7425],\n",
      "        [-0.7425]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Слой вида y = w @ x + b\n",
    "# Веса инициализируются случайными числами\n",
    "# bias=False означает \"b=0 всегда\"\n",
    "lin_1 = nn.Linear(2, 1)\n",
    "# Принимает тензор размерности (bs, in_features)\n",
    "# bs - batch_size, размер батча\n",
    "# in_features - размерность каждого вектора, в нашем случае 2\n",
    "y = lin_1(torch.ones((3, 2)))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5532, -0.4757]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0.2864], requires_grad=True)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# У линейного слоя есть веса (weight) и смещение (bias), его можно получить\n",
    "print(lin_1.weight)\n",
    "print()\n",
    "print(lin_1.bias)\n",
    "print()\n",
    "lin_2 = nn.Linear(2, 1, bias=False)\n",
    "# bias будет None, если его отключить (см. выше)\n",
    "print(lin_2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311, 0.7311]])\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n",
      "\n",
      "tensor([[0.3841],\n",
      "        [0.3841],\n",
      "        [0.3841]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Но в лекции говорили, что нужна еще нелинейность.\n",
    "# Ее тоже можно найти в torch.nn\n",
    "act = nn.Sigmoid()\n",
    "print(act(torch.ones((2, 4))))\n",
    "print()\n",
    "# соберем все воедино\n",
    "# nn.Sequential позволяет задать несколько слоев подряд\n",
    "fc = nn.Sequential(nn.Linear(2, 1, bias=True), nn.Sigmoid())\n",
    "print(fc)\n",
    "print()\n",
    "print(fc(torch.ones((3, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (i_am_layer): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (i_am_activation): Sigmoid()\n",
      ")\n",
      "\n",
      "Linear(in_features=2, out_features=1, bias=True)\n",
      "\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# В Sequential можно задать имена слоям через OrderedDict\n",
    "from collections import OrderedDict\n",
    "\n",
    "fc = nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            (\"i_am_layer\", nn.Linear(2, 1)),\n",
    "            (\"i_am_activation\", nn.Sigmoid()),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(fc)\n",
    "print()\n",
    "# слои можно достать по имени (как поле) или по индексу\n",
    "print(fc[0])\n",
    "print()\n",
    "# ради такой возможности и заводят слои через OrderedDict\n",
    "print(fc.i_am_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch и видеокарта\n",
    "Четвертая причина популярности PyTorch: удобная работа с видеокартой.\n",
    "Давайте посмотрим, как это делается.\n",
    "\n",
    "С чем мы познакомимся:\n",
    "- операции `.to()`, `.cuda()`, `.cpu()` для ускорения вычислений\n",
    "- утилита `nvidia-smi` для отслеживания здоровья видеокарты\n",
    "- демонстрация скорости — насколько же видеокарта быстрее процессора?\n",
    "- какие бывают проблемы с видеокартой и как их решать на примере `device assert triggered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 3.])\n",
      "cpu\n",
      "\n",
      "tensor([1., 3.], device='cuda:0')\n",
      "cuda:0\n",
      "\n",
      "tensor([1., 3.])\n",
      "cpu\n",
      "\n",
      "tensor([1., 3.], device='cuda:0')\n",
      "cuda:0\n",
      "\n",
      "tensor([1., 3.])\n",
      "cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 3.0])\n",
    "print(a)\n",
    "# Каждый тензор лежит либо в RAM (она принадлежит CPU), либо в GPU - это можно узнать по .device\n",
    "print(a.device)\n",
    "print()\n",
    "# Тензор легко можно перенести на GPU\n",
    "a = a.to(\"cuda\")\n",
    "# Теперь у нас тензор на GPU.\n",
    "print(a)\n",
    "print(a.device)\n",
    "print()\n",
    "# А теперь - обратно на CPU\n",
    "a = a.to(\"cpu\")\n",
    "print(a)\n",
    "print(a.device)\n",
    "print()\n",
    "# Перенести на GPU можно также командой .cuda()\n",
    "# Если тензор уже на видеокарте, то .cuda() ничего не будет делать\n",
    "a = a.cuda()\n",
    "print(a)\n",
    "print(a.device)\n",
    "print()\n",
    "# Аналогично можно перенести на CPU через .cpu()\n",
    "a = a.cpu()\n",
    "print(a)\n",
    "print(a.device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Главное правило - нельзя перемешивать тензоры на видеокарте и тензоры на CPU.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Либо все операции на CPU, либо на GPU.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Можно какие-то промежуточные значения гонять туда-сюда, но это будет медленно.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Так, код ниже не сработает.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# Главное правило - нельзя перемешивать тензоры на видеокарте и тензоры на CPU.\n",
    "# Либо все операции на CPU, либо на GPU.\n",
    "# Можно какие-то промежуточные значения гонять туда-сюда, но это будет медленно.\n",
    "# Так, код ниже не сработает.\n",
    "torch.zeros((2, 3), device=\"cuda\") + torch.zeros((2, 3), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 14 23:33:22 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.40.07              Driver Version: 551.52         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   36C    P5             24W /  340W |    1487MiB /  16376MiB |     21%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     73001      C   /python3.10                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# GPU не безлимитна. Хочется узнать, сколько ресурсов GPU мы занимаем.\n",
    "# Для этого есть nvidia-smi\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим, что процесс python3.10 что-то занимает. Это как раз наши тензоры.\n",
    "# У вас будут другие числа - все сильно зависит от модели видеокарты и операционной системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В чем же такой плюс от работы на GPU?\n",
    "\n",
    "Давайте увидим сами. Возьмем большой тензор и начнем его умножать большое число раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7fc022429390>\n",
      "many_layers(data)\n",
      "  11.31 s\n",
      "  1 measurement, 5 runs , 8 threads\n"
     ]
    }
   ],
   "source": [
    "# Используем benchmark из pytorch - он сделает \"честное\" вычисление (без кешей, с прогревом и т.п.)\n",
    "# Подробнее про benchmark в PyTorch: https://pytorch.org/tutorials/recipes/recipes/benchmark.html\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "num_channels = 4096\n",
    "many_layers = nn.Sequential(*[nn.Linear(num_channels, num_channels)] * 100)\n",
    "data = torch.randn((3000, num_channels))\n",
    "# Прогоним через слой 5 раз и подсчитаем среднее/дисперсию\n",
    "t = benchmark.Timer(\n",
    "    stmt=\"many_layers(data)\",\n",
    "    globals={\"many_layers\": many_layers, \"data\": data},\n",
    "    # заметьте, используем 8 ядер процессора\n",
    "    num_threads=8,\n",
    ")\n",
    "print(t.timeit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7fc022429d50>\n",
      "many_layers_gpu(data_gpu)\n",
      "  379.86 ms\n",
      "  1 measurement, 5 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "# Повторим эксперимент, но уже на GPU\n",
    "\n",
    "many_layers_gpu = many_layers.to(\"cuda\")\n",
    "data_gpu = data.to(\"cuda\")\n",
    "t = benchmark.Timer(\n",
    "    stmt=\"many_layers_gpu(data_gpu)\",\n",
    "    globals={\"many_layers_gpu\": many_layers_gpu, \"data_gpu\": data_gpu},\n",
    ")\n",
    "print(t.timeit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 30 раз быстрее! И это только игрушечный пример.\n",
    "В реальных сетях разница может быть еще больше.\n",
    "\n",
    "В чем же подвох? Почему бы все не учить на видеокарте?\n",
    "Есть две причины, которые остановят нас:\n",
    "1. У видеокарты очень мало оперативной памяти по сравнению с сервером.\n",
    "На сервере вы можете поставить и 512 Гб оперативной памяти, и даже 1 Тб.\n",
    "Но на видеокарте сейчас можно ставить до 80 Гб (Tesla H800).\n",
    "2. На видеокарте не очень информативные ошибки. Это особенность программы CUDA,\n",
    "которую PyTorch использует для вычислений на видеокарте.\n",
    "\n",
    "Первая проблема фундаментальная, ее решают через распределение нагрузки по нескольким видеокартам.\n",
    "Это делать сложно: нужно научить несколько GPU взаимодействовать друг с другом, распределять равномерно нагрузку\n",
    "и синхронизировать работу.\n",
    "На первых порах вам вряд ли придется столкнуться с такой задачей, поэтому пока оставим эту тему.\n",
    "\n",
    "Рассмотрим вторую проблему с неинформативными ошибками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Подсчитаем Binary Cross Entropy loss с элементами вне {0, 1}\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:3127\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3125\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "# Подсчитаем Binary Cross Entropy loss с элементами вне {0, 1}\n",
    "nn.BCELoss()(torch.arange(2, 3).float(), torch.arange(2, 3).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# То же самое, но тензор на GPU\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:3127\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3125\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# То же самое, но тензор на GPU\n",
    "nn.BCELoss()(torch.arange(2, 3).float().cuda(), torch.arange(2, 3).float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Более того - после ошибки уже ничего нельзя сделать с видеокартой.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Придется перезапускать ноутбук :(\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Более того - после ошибки уже ничего нельзя сделать с видеокартой.\n",
    "# Придется перезапускать ноутбук :(\n",
    "torch.randn((2, 3), device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за таких проблем на видеокарте не рекомендуется отлаживать модели (об этом говорили в лекции)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
