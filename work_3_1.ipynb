{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3\n",
    "\n",
    "В этом задании напишем простое решение классификации датасета `FashionMNIST`, а затем будем его улучшать с помощью:\n",
    "- dropout;\n",
    "- batch normalization;\n",
    "- LR scheduler;\n",
    "\n",
    "В конце сохраним модель в файл и убедимся, что этот файл можем в дальнейшем прочитать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xARvjMxP4JWd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from dataclasses import dataclass\n",
    "import tqdm\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.sgd import SGD\n",
    "import typing as tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fmMiGhR4SDH",
    "outputId": "0abdee61-985b-45e3-b5b2-5bc07c81cf9b"
   },
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "test_dataset = FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "egta3KBe4fkg"
   },
   "outputs": [],
   "source": [
    "X_train = train_dataset.data.float()\n",
    "y_train = train_dataset.targets\n",
    "X_test = test_dataset.data.float()\n",
    "y_test = test_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PvVbvSjN5KnY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Для оценки будем использовать метрику accuracy\n",
    "# Подумайте (опционально), какие еще метрики можно использовать\n",
    "def calculate_accuracy(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    correct = (predicted == y_true).float().sum()\n",
    "    accuracy = correct / y_true.shape[0]\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №1\n",
    "\n",
    "Попробуйте реализовать простой бейзлайн с несколькими слоями:\n",
    "- Linear\n",
    "- ReLU\n",
    "- Linear\n",
    "\n",
    "Вставьте свою релизацию `SimpleModel` в проверку.\n",
    "Вам нужно дописать и сдать как `SimpleModel`, так и `train_loop`.\n",
    "\n",
    "Используйте кросс-энтропию как функцию потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/theo/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtheotheo46\u001b[0m (\u001b[33mtheotheo46-trs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key = 'cc603ae0565bbbfce5cc5b068a9bddabb8950920')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Orzur80V5J9j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/theo/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/theo/karpov/nlp/wandb/run-20250201_184546-c4cyh6de</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/theotheo46-trs/simple-model-train/runs/c4cyh6de' target=\"_blank\">giddy-wave-55</a></strong> to <a href='https://wandb.ai/theotheo46-trs/simple-model-train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/theotheo46-trs/simple-model-train' target=\"_blank\">https://wandb.ai/theotheo46-trs/simple-model-train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/theotheo46-trs/simple-model-train/runs/c4cyh6de' target=\"_blank\">https://wandb.ai/theotheo46-trs/simple-model-train/runs/c4cyh6de</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:18<00:00,  2.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss_train</td><td>█▇▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8201</td></tr><tr><td>iteration</td><td>199</td></tr><tr><td>loss_train</td><td>0.54891</td></tr><tr><td>lr</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-wave-55</strong> at: <a href='https://wandb.ai/theotheo46-trs/simple-model-train/runs/c4cyh6de' target=\"_blank\">https://wandb.ai/theotheo46-trs/simple-model-train/runs/c4cyh6de</a><br> View project at: <a href='https://wandb.ai/theotheo46-trs/simple-model-train' target=\"_blank\">https://wandb.ai/theotheo46-trs/simple-model-train</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250201_184546-c4cyh6de/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8201000094413757\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.sgd import SGD\n",
    "import tqdm\n",
    "import typing as tp\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    lr: float = 1e-2\n",
    "    total_iterations: int = 200\n",
    "    step_size: int = 30\n",
    "    gamma: float = 0.5\n",
    "    eval_every: int = 10\n",
    "\n",
    "class ExpModel(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(ExpModel, self).__init__()\n",
    "        hidden_dim = 512\n",
    "        dropout_rate = 0.3\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=28 * 28, out_features=hidden_dim),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=hidden_dim),\n",
    "            nn.Linear(in_features=hidden_dim, out_features=num_classes),\n",
    "            # nn.Softmax(dim=1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.reshape((-1, 28 * 28))\n",
    "        return self.net(x)\n",
    "\n",
    "def train_loop(\n",
    "    model: ExpModel,\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    X_val: torch.Tensor,\n",
    "    y_val: torch.Tensor,\n",
    "    config: TrainConfig,\n",
    "):\n",
    "    \"\"\"Обучите здесь модель, подсчитайте метрики на валидационной выборке.\n",
    "\n",
    "    Можете так же писать/рисовать accuracy в процессе обучения.\n",
    "    Например, каждые 10 итераций или даже каждую итерацию.\n",
    "    \"\"\"\n",
    "    wandb.login(key = 'cc603ae0565bbbfce5cc5b068a9bddabb8950920')\n",
    "    wandb.init(\n",
    "        project=\"simple-model-train\",\n",
    "        notes=\"version 1\",\n",
    "        tags=[\"sgd\", \"2-layer\"],\n",
    "        config=config,\n",
    "    )\n",
    "    optimizer = SGD(model.parameters(), lr=config.lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, config.step_size, config.gamma)\n",
    "\n",
    "    model.train()\n",
    "    mac_accuracy = 0\n",
    "    for i in tqdm.trange(config.total_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(X_train), y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        metrics = {\"iteration\": i, \"loss_train\": loss.detach().cpu().item()}\n",
    "        # каждые `eval_every` итераций будем считать метрику на отложенной выборке\n",
    "        if (i + 1) % config.eval_every == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                accuracy = calculate_accuracy(model(X_val), y_val)\n",
    "                if accuracy > mac_accuracy:\n",
    "                    mac_accuracy = accuracy\n",
    "\n",
    "                model.train()\n",
    "                metrics.update({\"accuracy\": accuracy})\n",
    "                scheduler.step()\n",
    "                metrics.update({\"lr\": scheduler.get_last_lr()[0]})\n",
    "\n",
    "\n",
    "        wandb.log(metrics)\n",
    "    wandb.finish()\n",
    "    print(mac_accuracy)\n",
    "\n",
    "torch.random.manual_seed(987)\n",
    "model = ExpModel(num_classes=len(y_train.unique()))\n",
    "config = TrainConfig()\n",
    "train_loop(model, X_train, y_train, X_test, y_test, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №2\n",
    "Какое максимальное значение метрики accuracy удалось получить в процессе обучения?\n",
    "\n",
    "Округлите до 3 значений после запятой\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O8NRkaAe1xw",
    "outputId": "48506331-ddb5-4c50-f71e-c6ce49174522"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(987)\n",
    "# дефолтные значения\n",
    "config = TrainConfig()\n",
    "# Ваш код для обучения и подсчета accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №3\n",
    "Добавьте один `dropout` слой в вашу модель.\n",
    "\n",
    "_Подумайте, что может поменяться при перестановке ReLU и Dropout слоев местами._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-0l7KJ5t6MDo"
   },
   "outputs": [],
   "source": [
    "# Возможно, класс нужно отнаследовать от некого класса из pytorch\n",
    "class DropoutModel:\n",
    "    hidden_dim = 512\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HXca_LDEb-1",
    "outputId": "d1ed5c0d-8cbe-4537-feb0-ed8f420519a3"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(987)\n",
    "config = TrainConfig()\n",
    "# Ваш код для обучения и подсчета accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №4\n",
    "Какое максимальное значение accuracy получилось в ходе обучения модели? \n",
    "\n",
    "Округлите до 3х знаков после запятой и отправьте в ЛМС."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQoHAYnR91x-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xdis_LAvLoNJ"
   },
   "source": [
    "## Задание №5\n",
    "\n",
    "Добавьте `BatchNorm` в вашу модель.\n",
    "Отправьте в ЛМС реализацию.\n",
    "\n",
    "Стоит ли делать BatchNorm до ReLU или после него?\n",
    "Это дискуссионный вопрос, чаще всего применяют сначала нелинейность, затем Batch Norm.\n",
    "Один из аргументов: при таком подходе данные на выходе будут иметь среднее 0 - что и ожидают люди, когда добавляют нормализацию.\n",
    "\n",
    "_[Дискуссия на Reddit](https://www.reddit.com/r/MachineLearning/comments/67gonq/d_batch_normalization_before_or_after_relu/)_\n",
    "\n",
    "Для определенности в этом задании будем следовать такому порядку: сначала ReLU, затем Batch Norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gm4LCPfW7wYJ"
   },
   "outputs": [],
   "source": [
    "# Возможно, класс нужно отнаследовать от некого класса из pytorch\n",
    "class BatchNormModel:\n",
    "    hidden_dim = 512\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaAkxSf-LsHp",
    "outputId": "350528f2-2c6a-4e4c-cf50-a8fdc3f5d3f5"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(987)\n",
    "config = TrainConfig()\n",
    "# Ваш код для обучения и подсчета accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №6\n",
    "Какое максимальное значение `accuracy` получилось в ходе обучения модели? \n",
    "\n",
    "Округлите до 3х знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат batch normalization мог не особо порадовать.\n",
    "Но не спешите с выводами насчет этого слоя!\n",
    "\n",
    "Попробуйте обучить заново все три модели со значением `lr=1e-2` (в 10 раз больше).\n",
    "Сравните результаты моделей и сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №7\n",
    "Добавьте `LRscheduler` в вашу модель.\n",
    "\n",
    "Подробнее про `schedulers` можно почитать в [документации](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6cMUEd9G-5Bi"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "def train_loop_with_scheduler(\n",
    "    model,\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    X_val: torch.Tensor,\n",
    "    y_val: torch.Tensor,\n",
    "    config: TrainConfig,\n",
    "):\n",
    "    ...\n",
    "    scheduler = StepLR(..., step_size=5, gamma=0.1)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uf39c7d-BU1a",
    "outputId": "9133cfa4-213a-424d-b964-c1006f649698"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(987)\n",
    "config = TrainConfig(lr=1e-3)\n",
    "# Ваш код для обучения и подсчета accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №8\n",
    "\n",
    "Поэксперементируйте с параметрами нейронной сети, попробуйте добиться максимальной метрики `accuracy`.\n",
    "\n",
    "- попробуйте комбинацию Drouput + Batch Normalization и подумайте, как лучше всего раскрыть силу batch normalization (вспомните эксперименты с lr);\n",
    "- попробуйте подвигать вероятность в Dropout;\n",
    "- ну, или подержите обучение подольше, поставив больше шагов :)\n",
    "\n",
    "В ЛМС нужно сдать код класса `ExpModel`.\n",
    "Вам необходимо выбить accuracy > 80%, чтобы сдать этот пункт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(987)\n",
    "\n",
    "\n",
    "# Ваш код модели и ее обучения при seed = 987\n",
    "class ExpModel: ...\n",
    "\n",
    "\n",
    "model = ExpModel()\n",
    "config = TrainConfig(...)\n",
    "train_loop(model, X_train, y_train, X_test, y_test, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, сохраним лучшую модель, чтобы в будущем ее могли взять и использовать, без обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №9\n",
    "\n",
    "Напишите код, который сохранит модель в файл `model.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gKwBP2V4CCJu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lmsl_0HnBuJH",
    "outputId": "470a7f54-af5c-48aa-e8a1-86b05bbc26b2"
   },
   "outputs": [],
   "source": [
    "# Впоследствии эту модель можно будет загрузить вот так:\n",
    "model_loaded = ExpModel(num_classes=len(y_test.unique()))\n",
    "model_loaded.load_state_dict(torch.load(\"model.pt\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
