{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnNvfQkzvdgh"
      },
      "source": [
        "# Урок 9. Часть 1\n",
        "\n",
        "1. Смотрим на работу Gemma 2B.\n",
        "1. Решаем задачи с помощью Gemma 2B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAXBnJABvdgk"
      },
      "source": [
        "## Gemma 2B\n",
        "\n",
        "1. Ссылка на kaggle.com https://www.kaggle.com/models/google/gemma\n",
        "1. Ссылка на huggingface.co https://huggingface.co/google/gemma-1.1-2b-it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "fQlvK7_zvdgk"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "\n",
        "# Загружаем модель\n",
        "model_path = \"/kaggle/input/gemma/transformers/1.1-2b-it/1/\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\", revision=\"float16\").eval()\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKaTWwj3vdgl"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCWi8j8Rvdgm"
      },
      "outputs": [],
      "source": [
        "model.lm_head.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKf8QVoQvdgm"
      },
      "outputs": [],
      "source": [
        "# Токенизируем текст\n",
        "input_text = \"Write me a poem about Machine Learning.\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH4lCG8-vdgm"
      },
      "outputs": [],
      "source": [
        "# Первая генерация текста\n",
        "outputs = model.generate(**input_ids, max_new_tokens=20)\n",
        "\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nocOmwHdvdgm"
      },
      "outputs": [],
      "source": [
        "# Токенизируем как чат, модель училась общаться в формате диалога\n",
        "conversation = [{\"role\": \"user\", \"content\": \"Write me a poem about Machine Learning.\"}]\n",
        "input_ids = tokenizer.apply_chat_template(conversation, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "print(tokenizer.batch_decode(input_ids)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqUDpmMhvdgn"
      },
      "outputs": [],
      "source": [
        "# Вторая генерация текста\n",
        "generate_ids = model.generate(input_ids, max_new_tokens=20)\n",
        "\n",
        "print(tokenizer.batch_decode(generate_ids)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHRw7Uwqvdgn"
      },
      "outputs": [],
      "source": [
        "new_tokens = generate_ids[0, input_ids.shape[-1]:]\n",
        "\n",
        "print(tokenizer.decode(new_tokens, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lja8wiB8vdgn"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "def measure_time(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()  # Record the start time\n",
        "        result = func(*args, **kwargs)  # Call the actual function\n",
        "        end_time = time.time()  # Record the end time\n",
        "        elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
        "        print(f\"Function '{func.__name__}' took {elapsed_time:.4f} seconds to complete.\\n\")\n",
        "        return result  # Return the result of the function\n",
        "    return wrapper\n",
        "\n",
        "# Напишем функцию для генерации текста - ответа на сообщение пользователя\n",
        "@measure_time\n",
        "@torch.inference_mode()\n",
        "def generate_text(prompt, **kwargs):\n",
        "    conversation = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    input_ids = tokenizer.apply_chat_template(conversation, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "    generate_ids = model.generate(input_ids, **kwargs)\n",
        "    new_tokens = generate_ids[0, input_ids.shape[-1]:]\n",
        "    return tokenizer.decode(new_tokens, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J_i19Acvdgn"
      },
      "outputs": [],
      "source": [
        "print(generate_text(\"Hello!\", max_new_tokens=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7uflPgCvdgo"
      },
      "source": [
        "### Температура\n",
        "\n",
        "Параметр температуры в LLM контролирует случайность предсказаний. Низкие значения температуры делают модель более детерминированной, в то время как высокие значения температуры делают ее более креативной и разнообразной. Вот общие рекомендации по настройке температуры:\n",
        "\n",
        "1. **Низкая температура (0.1 - 0.3)**:\n",
        "   - Результаты становятся более детерминированными и сфокусированными\n",
        "   - Хорошо подходит для задач, требующих точности, таких как ответы на фактические вопросы или генерация кода\n",
        "   - Меньше вероятность получения неожиданных или креативных ответов\n",
        "\n",
        "2. **Средняя температура (0.4 - 0.7)**:\n",
        "   - Балансирует между случайностью и детерминизмом\n",
        "   - Подходит для большинства задач общего назначения\n",
        "   - Обеспечивает связные, но несколько разнообразные результаты\n",
        "\n",
        "3. **Высокая температура (0.8 - 1.0)**:\n",
        "   - Увеличивает креативность и разнообразие в ответах\n",
        "   - Полезна для творческого письма, мозговых штурмов или создания поэзии\n",
        "   - Ответы могут быть менее предсказуемыми и более разнообразными\n",
        "\n",
        "4. **Очень высокая температура (выше 1.0)**:\n",
        "   - Может приводить к очень разнообразным и иногда бессмысленным результатам\n",
        "   - Обычно не рекомендуется для большинства задач, но можно экспериментировать для высоко креативных задач\n",
        "\n",
        "### Практические рекомендации:\n",
        "- **0.7**: Часто является хорошим выбором по умолчанию для сбалансированных результатов\n",
        "- **0.5**: Хорошо подходит для смешения креативности и связности\n",
        "- **0.2**: Идеально для задач, требующих высокой точности и последовательности\n",
        "\n",
        "Настройка температуры позволяет точно настроить поведение языковой модели для выполнения конкретных задач, поэтому эксперименты в этих диапазонах помогут достичь желаемого стиля вывода."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3V44aV_vdgo"
      },
      "outputs": [],
      "source": [
        "# Генерируем с разной температурой\n",
        "temperature_values = [0.1, 0.3, 0.5, 0.75, 1.0, 1.5]\n",
        "\n",
        "for temperature in temperature_values:\n",
        "    print(f\"{temperature=}\", end=\"\\n\\n\")\n",
        "    print(generate_text(\"Write me a haiku about deep learning\", max_new_tokens=100, temperature=temperature, do_sample=True))\n",
        "    print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ihsSL_vdgo"
      },
      "source": [
        "## Решаем задачи с помощью Gemma 2B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT7tWaAevdgo"
      },
      "source": [
        "### Саммаризация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKRqQwfYvdgo"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "The temperature parameter in language models (LLMs) controls the randomness of the predictions. Lower temperatures make the model more deterministic, while higher temperatures make it more creative and diverse. Here are some general guidelines for setting the temperature:\n",
        "\n",
        "1. **Low Temperature (0.1 - 0.3)**:\n",
        "   - Results in more deterministic and focused outputs.\n",
        "   - Good for tasks requiring precision, such as factual answers or code generation.\n",
        "   - The model is less likely to produce unexpected or creative responses.\n",
        "\n",
        "2. **Medium Temperature (0.4 - 0.7)**:\n",
        "   - Balances between randomness and determinism.\n",
        "   - Suitable for most general-purpose tasks.\n",
        "   - Produces coherent yet somewhat varied outputs.\n",
        "\n",
        "3. **High Temperature (0.8 - 1.0)**:\n",
        "   - Increases creativity and diversity in responses.\n",
        "   - Useful for creative writing, brainstorming, or generating poetry.\n",
        "   - Outputs may be less predictable and more varied.\n",
        "\n",
        "4. **Very High Temperature (above 1.0)**:\n",
        "   - Can produce highly diverse and sometimes nonsensical outputs.\n",
        "   - Generally not recommended for most tasks but can be experimented with for highly creative tasks.\n",
        "\n",
        "### Practical Recommendations:\n",
        "- **0.7**: Often a good default choice for balanced outputs.\n",
        "- **0.5**: Good for a mix of creativity and coherence.\n",
        "- **0.2**: Ideal for tasks requiring high accuracy and consistency.\n",
        "\n",
        "Adjusting the temperature allows you to fine-tune the behavior of the language model to suit specific needs, so experimenting within these ranges can help you achieve the desired output style.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"Summarize the following text in 2-3 sentences, capturing the main points and key details while maintaining coherence and accuracy. Ensure the summary is concise and informative.\n",
        "\n",
        "'''\n",
        "{text}\n",
        "'''\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUa72zaCvdgo"
      },
      "outputs": [],
      "source": [
        "print(generate_text(prompt, temperature=0.2, do_sample=True, max_new_tokens=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8KLoMOPvdgo"
      },
      "source": [
        "### Определение тональности текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiBMLHouvdgo"
      },
      "outputs": [],
      "source": [
        "text = \"This new GPT4o is a complete disaster. It's slow, inaccurate, and difficult to use. I hate it very much, the Google's Gemma is sooo better.\"\n",
        "\n",
        "prompt = f\"\"\"Determine the sentiment of this text. Return only sentiment.\n",
        "\n",
        "'''\n",
        "{text}\n",
        "'''\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucak2uMHvdgo"
      },
      "outputs": [],
      "source": [
        "print(generate_text(prompt, temperature=0.2, do_sample=True, max_new_tokens=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJCiQlacvdgp"
      },
      "source": [
        "### Классификация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0tk_bt0vdgp"
      },
      "outputs": [],
      "source": [
        "text = \"The latest smartphone from Apple has received super positive reviews for its sleek design and powerful performance. But it is very expensive, so think for yourself!\"\n",
        "prompt = f\"\"\"Classify the following text into one of the categories: technology, sports, politics. Return only a category.\n",
        "\n",
        "'''\n",
        "{text}\n",
        "'''\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaChVfQCvdgp"
      },
      "outputs": [],
      "source": [
        "print(generate_text(prompt, temperature=0.2, do_sample=True, max_new_tokens=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Io3P0govdgp"
      },
      "source": [
        "### Перевод"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR-2R4xtvdgp"
      },
      "outputs": [],
      "source": [
        "text = \"Биршерт Алексей Дмитриевич записывает лекцию и семинар для 9 занятия по курсу Глубинное обучение.\"\n",
        "source_language = \"russian\"\n",
        "target_language = \"spanish\"\n",
        "\n",
        "prompt = f\"\"\"Translate this text from {source_language} to {target_language}. Return only translation.\n",
        "\n",
        "'''\n",
        "{text}\n",
        "'''\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3w1yTj2vdgp"
      },
      "outputs": [],
      "source": [
        "translation = generate_text(prompt, temperature=0.7, do_sample=True, max_new_tokens=100)\n",
        "\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSn-Ocf6vdgp"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Translate this text from {target_language} to {source_language}. Return only translation.\n",
        "\n",
        "'''\n",
        "{translation}\n",
        "'''\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjwk7W6Mvdgp"
      },
      "outputs": [],
      "source": [
        "back_translation = generate_text(prompt, temperature=0.7, do_sample=True, max_new_tokens=100)\n",
        "\n",
        "print(back_translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxUnZpHRvdgp"
      },
      "source": [
        "### Ответы на вопросы по тексту\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H0TRpxNvdgp"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Jason Statham is an English actor and former competitive diver, best known for his roles in action-thriller films. Born on July 26, 1967, in Shirebrook, Derbyshire, England, Statham's journey to stardom is as remarkable as the characters he portrays. Before entering the film industry, he was a member of Britain's National Diving Squad for over a decade, competing at world championships and the Commonwealth Games. His rugged good looks and athletic build, combined with his martial arts skills, made him a natural fit for the action genre.\n",
        "\n",
        "Statham's film career began in 1998 when he was cast in Guy Ritchie's crime comedy \"Lock, Stock and Two Smoking Barrels.\" His performance caught the attention of audiences and critics alike, leading to a follow-up role in Ritchie's \"Snatch\" (2000), where he starred alongside Brad Pitt and Benicio del Toro. These early roles established him as a reliable actor capable of delivering tough, street-smart characters with a touch of humor.\n",
        "\n",
        "He gained international fame with his role as Frank Martin in \"The Transporter\" series (2002-2008), where he performed many of his own stunts, showcasing his skills in martial arts, driving, and combat. This franchise solidified his reputation as a top-tier action star. Statham continued to build on this success with roles in high-profile action films such as \"Crank\" (2006), \"War\" (2007), and \"Death Race\" (2008).\n",
        "\n",
        "In 2010, Statham joined the ensemble cast of \"The Expendables,\" alongside other action legends like Sylvester Stallone and Arnold Schwarzenegger. The film's success led to two sequels, further cementing his status in Hollywood. He also became part of the \"Fast & Furious\" franchise, debuting as the villain Deckard Shaw in \"Fast & Furious 6\" (2013) and reprising the role in subsequent films, including \"Furious 7\" (2015), \"The Fate of the Furious\" (2017), and the spin-off \"Hobbs & Shaw\" (2019).\n",
        "\n",
        "Statham's appeal lies in his ability to bring authenticity to his roles, performing stunts and fight scenes with a level of realism that resonates with audiences. Off-screen, he is known for his private and low-key lifestyle, a stark contrast to the high-octane characters he portrays. He has been in a long-term relationship with model Rosie Huntington-Whiteley, with whom he shares a son.\n",
        "\n",
        "Jason Statham's career is a testament to his versatility and dedication to his craft. From his beginnings as a competitive diver to becoming one of Hollywood's most bankable action stars, he has consistently delivered performances that are both compelling and entertaining. His contributions to the action genre have earned him a loyal fan base and a lasting legacy in the film industry.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzBmmNrbvdgp"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What were Jason Statham's professions before he became an actor?\",\n",
        "    \"Which film marked the beginning of Jason Statham's film career in 1998?\",\n",
        "    \"How did Jason Statham's role in 'The Transporter' series impact his career?\",\n",
        "    \"In which film franchise did Jason Statham play the character Deckard Shaw?\",\n",
        "    \"Who is Jason Statham's long-term partner, and do they have any children?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNZGemmlvdgq"
      },
      "outputs": [],
      "source": [
        "for question in questions:\n",
        "    print(question, end=\"\\n\\n\")\n",
        "\n",
        "    prompt = f\"\"\"Answer the question based on the context provided:\n",
        "\n",
        "QUESTION\n",
        "{question}\n",
        "\n",
        "'''CONTEXT\n",
        "{text}\n",
        "'''\n",
        "    \"\"\"\n",
        "    print(generate_text(prompt, temperature=0.7, do_sample=True, max_new_tokens=100))\n",
        "\n",
        "    print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrPs2clmvdgq"
      },
      "source": [
        "### Ответы на вопросы PRO MAX ULTRA PLUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZrNUyxXvdgq"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"\"\"Cats are fascinating creatures, beloved by millions worldwide for their independent yet affectionate nature. Domesticated over 4,000 years ago in ancient Egypt, cats were initially valued for their ability to control vermin. Over time, they became symbols of grace and mystery, a status they still hold today.\n",
        "\n",
        "One of the most striking features of cats is their agility. Their bodies are designed for hunting and climbing, with flexible spines and powerful hind legs allowing them to leap great distances. A cat's retractable claws are perfect for capturing prey and climbing, while their keen senses of sight and hearing make them excellent hunters.\n",
        "\n",
        "Cats are known for their meticulous grooming habits. They spend a significant portion of their day licking their fur to keep it clean and free of parasites. This behavior also serves to regulate their body temperature and reinforce social bonds when they groom each other.\n",
        "\n",
        "Despite their reputation for independence, many cats form strong attachments to their owners. They communicate through a variety of vocalizations, including purring, meowing, and hissing. Purring, often associated with contentment, can also be a self-soothing mechanism when they are in pain or stressed.\n",
        "\n",
        "Cats have a unique social structure. Unlike dogs, which are pack animals, cats are solitary hunters. However, they can be quite social when they feel secure, often forming close bonds with other cats and even other species, including humans. Their ability to adapt to various environments makes them popular pets in urban and rural settings alike.\n",
        "\n",
        "In terms of health, cats are generally robust animals, but they do require regular veterinary care. Vaccinations, flea control, and a balanced diet are crucial for maintaining their health. Indoor cats tend to live longer than their outdoor counterparts, as they are less exposed to diseases, accidents, and predators.\n",
        "\n",
        "In conclusion, cats are complex, multifaceted animals that bring joy and companionship to many households. Their blend of independence and affection, coupled with their graceful demeanor and playful antics, make them one of the most cherished pets globally.\"\"\",\n",
        "\n",
        "    \"\"\"The world's oceans, covering more than 70% of the Earth's surface, are essential to life on our planet. They regulate the climate, provide food, and support countless species, from the smallest plankton to the largest whales.\n",
        "\n",
        "The five main oceans – the Pacific, Atlantic, Indian, Southern, and Arctic – are interconnected and influence global weather patterns. The Pacific Ocean, the largest, spans over 60 million square miles and is home to the Mariana Trench, the deepest point on Earth. The Atlantic Ocean, known for its vital role in trade and history, connects the Americas with Europe and Africa. The Indian Ocean, crucial for monsoon patterns, supports a rich diversity of marine life. The Southern Ocean, encircling Antarctica, plays a critical role in regulating the Earth's temperature. The Arctic Ocean, the smallest and shallowest, is significant for its unique polar ecosystems and rapidly changing ice cover.\n",
        "\n",
        "Oceans are a major source of biodiversity. Coral reefs, often called the \"rainforests of the sea,\" provide habitat for a quarter of all marine species. Mangroves and seagrass beds are essential for carbon sequestration and serve as nurseries for many fish species. The open ocean, though appearing barren, supports life from microscopic phytoplankton to massive blue whales.\n",
        "\n",
        "Human activities have increasingly impacted oceans. Overfishing, pollution, and climate change are major threats. Overfishing depletes fish stocks and disrupts marine ecosystems. Pollution, including plastics and chemical runoff, harms marine life and enters the food chain, affecting human health. Climate change causes ocean acidification and warming, which bleach coral reefs and alter the habitats of many species.\n",
        "\n",
        "Conservation efforts are vital. Marine protected areas (MPAs), sustainable fishing practices, and pollution controls can help preserve ocean health. International cooperation, like the Paris Agreement, aims to address climate change's impacts on oceans. Protecting the oceans is crucial not only for marine life but for the well-being of future generations. Understanding and mitigating human impact on oceans is imperative for maintaining their ecological balance and the planet's health.\"\"\",\n",
        "\n",
        "    \"\"\"Paris, often referred to as the \"City of Light,\" is renowned for its rich history, stunning architecture, and vibrant cultural scene. As the capital of France, Paris is a major European city and a global center for art, fashion, gastronomy, and culture.\n",
        "\n",
        "The city's layout is defined by its grand boulevards, iconic landmarks, and the Seine River, which divides Paris into the Left Bank and the Right Bank. The Eiffel Tower, one of the most recognizable structures in the world, offers breathtaking views of the city. Nearby, the Champs-Élysées stretches from the Arc de Triomphe to the Place de la Concorde, lined with shops, theaters, and cafes.\n",
        "\n",
        "Paris is also home to some of the world's most famous museums. The Louvre, originally a royal palace, houses thousands of works of art, including Leonardo da Vinci's \"Mona Lisa\" and the ancient Greek statue, \"Venus de Milo.\" The Musée d'Orsay, located in a former railway station, showcases an extensive collection of Impressionist and Post-Impressionist masterpieces by artists such as Monet, Van Gogh, and Degas.\n",
        "\n",
        "The city's architecture is a blend of historical and contemporary styles. The Gothic Notre-Dame Cathedral, despite the devastating fire in 2019, remains a symbol of French heritage. Modern architectural feats like the glass pyramid entrance to the Louvre and the futuristic design of the La Défense business district highlight Paris's innovative spirit.\n",
        "\n",
        "Parisian cuisine is celebrated worldwide. From the rustic charm of traditional bistros to the elegance of Michelin-starred restaurants, the city's culinary scene is diverse and exquisite. Delicacies like croissants, escargot, and crème brûlée, paired with fine wines, define the gastronomic experience.\n",
        "\n",
        "Paris is also a hub of fashion and design. The city's Fashion Week attracts global attention, and its boutiques and ateliers showcase cutting-edge trends. Renowned fashion houses like Chanel, Louis Vuitton, and Dior have their headquarters here, reinforcing Paris's status as a fashion capital.\n",
        "\n",
        "In essence, Paris is a city that effortlessly combines its historical roots with modern innovation, making it a timeless destination that captivates millions of visitors each year.\"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GmTFmALvdgq"
      },
      "source": [
        "Ссылка на модель https://huggingface.co/intfloat/multilingual-e5-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgzsEF2zvdgq"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "from transformers import AutoModel\n",
        "\n",
        "# Каждый текст должен начинаться для модели с \"query: \" или \"passage: \", даже если текст на русском.\n",
        "embedding_tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
        "embedding_model = AutoModel.from_pretrained('intfloat/multilingual-e5-large', device_map=\"auto\")\n",
        "\n",
        "for param in embedding_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-5NufRNvdgq"
      },
      "outputs": [],
      "source": [
        "def split_and_process_input_texts(input_texts, delimiter='\\n\\n'):\n",
        "    splited_texts = []\n",
        "\n",
        "    for text in input_texts:\n",
        "        splited_texts.extend([f\"passage: {part.strip()}\" for part in text.split(delimiter) if part.strip()])\n",
        "\n",
        "    return splited_texts\n",
        "\n",
        "\n",
        "splited_texts = split_and_process_input_texts(texts)\n",
        "\n",
        "batch_dict = embedding_tokenizer(splited_texts, max_length=512, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM_YlUtuvdgq"
      },
      "outputs": [],
      "source": [
        "batch_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLHeIPeEvdgu"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "\n",
        "outputs = embedding_model(**batch_dict)\n",
        "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "embeddings = F.normalize(embeddings, p=2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JBjls1Uvdgu"
      },
      "outputs": [],
      "source": [
        "def get_context(query: str) -> str:\n",
        "    query = f\"query: {query}\"\n",
        "\n",
        "    query_tokens = embedding_tokenizer([query], max_length=512, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
        "\n",
        "    query_outputs = embedding_model(**query_tokens)\n",
        "\n",
        "    query_embedding = average_pool(query_outputs.last_hidden_state, query_tokens['attention_mask'])\n",
        "\n",
        "    query_embedding = F.normalize(query_embedding, p=2, dim=1)\n",
        "\n",
        "    scores = (query_embedding @ embeddings.T) * 100\n",
        "    top_k_indices = scores[0].topk(5).indices\n",
        "\n",
        "    selected_texts = [splited_texts[idx].lstrip(\"passage: \") for idx in top_k_indices]\n",
        "    context_string = \"\\n\\n\".join(selected_texts)\n",
        "\n",
        "    return context_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTwpo-AWvdgu"
      },
      "outputs": [],
      "source": [
        "print(get_context(\"Who live in Paris?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWwkzRnvvdgu"
      },
      "outputs": [],
      "source": [
        "def answer_question(question: str) -> str:\n",
        "    context = get_context(question)\n",
        "\n",
        "    prompt = f\"\"\"You have access to a set of documents containing relevant information. Use these documents to answer the following question comprehensively and accurately. Ensure your response is detailed, specific, and directly addresses the question. Do not include any information that is not supported by the provided documents.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\"\"\"\n",
        "\n",
        "    return generate_text(prompt, temperature=0.7, do_sample=True, max_new_tokens=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8t3ACkUcvdgu"
      },
      "outputs": [],
      "source": [
        "cat_questions = [\n",
        "    \"What were cats initially valued for in ancient Egypt?\",\n",
        "    \"How do cats' retractable claws benefit them?\",\n",
        "    \"What is one reason why indoor cats tend to live longer than outdoor cats?\"\n",
        "]\n",
        "\n",
        "ocean_questions = [\n",
        "    \"What role does the Pacific Ocean play in global geography?\",\n",
        "    \"Why are coral reefs referred to as the 'rainforests of the sea'?\",\n",
        "    \"What are some major threats to the world's oceans caused by human activities?\"\n",
        "]\n",
        "\n",
        "paris_questions = [\n",
        "    \"What are some of the notable landmarks in Paris?\",\n",
        "    \"Which famous artworks can be found in the Louvre?\",\n",
        "    \"How does Paris combine historical and modern architectural styles?\"\n",
        "]\n",
        "\n",
        "questions = cat_questions + ocean_questions + paris_questions\n",
        "\n",
        "questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDFS4m9xvdgv"
      },
      "outputs": [],
      "source": [
        "for question in questions:\n",
        "    print(answer_question(question))\n",
        "    print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Gcipgyvdgv"
      },
      "source": [
        "## Резюме\n",
        "\n",
        "1. Загрузили модель Gemma с помощью библиотеки `Transformers`\n",
        "2. Вспомнили про температуру семплирования и попробовали разные температуры\n",
        "3. Порешали разные задачи с помощью Gemma\n",
        "4. Построили прототип RAG системы"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "modelInstanceId": 22003,
          "sourceId": 26140,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}