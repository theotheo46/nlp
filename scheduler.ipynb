{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\n\nБудем решать задачу классификации изображений Fashion MNIST с помощью полносвяных нейронных сетей. Напишем простое решение, а потом улучшим его.\n\n'''","metadata":{"id":"xARvjMxP4JWd","execution":{"iopub.status.busy":"2025-01-05T10:59:36.095803Z","iopub.execute_input":"2025-01-05T10:59:36.096034Z","iopub.status.idle":"2025-01-05T10:59:36.102344Z","shell.execute_reply.started":"2025-01-05T10:59:36.096012Z","shell.execute_reply":"2025-01-05T10:59:36.101520Z"},"trusted":true},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'\\n\\nБудем решать задачу классификации изображений Fashion MNIST с помощью полносвяных нейронных сетей. Напишем простое решение, а потом улучшим его.\\n\\n'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2025-01-05T11:03:54.720259Z","iopub.execute_input":"2025-01-05T11:03:54.720555Z","iopub.status.idle":"2025-01-05T11:03:58.382498Z","shell.execute_reply.started":"2025-01-05T11:03:54.720523Z","shell.execute_reply":"2025-01-05T11:03:58.381711Z"},"trusted":true},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"972e1a7e81b595b8a22b3c53552a91707540b820\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:07:36.374206Z","iopub.execute_input":"2025-01-06T06:07:36.374444Z","iopub.status.idle":"2025-01-06T06:07:44.282401Z","shell.execute_reply.started":"2025-01-06T06:07:36.374423Z","shell.execute_reply":"2025-01-06T06:07:44.281656Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamiralzgul\u001b[0m (\u001b[33mrncomp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision.datasets import FashionMNIST\nfrom torchvision.transforms import ToTensor\nfrom dataclasses import dataclass\nimport numpy as np\nfrom torch.optim.sgd import SGD\nfrom torch.optim.lr_scheduler import ExponentialLR, LinearLR, StepLR\nimport tqdm\nimport wandb\nfrom pathlib import Path\nimport tarfile\nimport http.client\n\n@dataclass\nclass TrainConfig:\n    lr: float = 0.1\n    eval_every: int = 10\n    total_iterations: int = 3000\n    scheduler_type: str = \"none\"\n    model_type: str = \"batch_norm\"\n    optimizer_type: str = \"sgd\"\n    gamma: float = 0.99  # Used for ExponentialLR if scheduler_type is \"exp\"\n\ndef set_seed(seed: int):\n    torch.cuda.manual_seed(seed)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n\ndef get_datasets():\n    train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=ToTensor())\n    test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=ToTensor())\n    return train_dataset, test_dataset\n\nclass GenericModel(nn.Module):\n    def __init__(self, num_classes=10, model_type=\"batch_norm\"):\n        super().__init__()\n        hidden_dim = 512\n        self.model_type = model_type\n        self.net = nn.Sequential(\n            nn.Linear(in_features=28*28, out_features=hidden_dim),\n            nn.ReLU(),\n            nn.BatchNorm1d(num_features=hidden_dim) if model_type == \"batch_norm\" else nn.Identity(),\n            nn.Linear(in_features=hidden_dim, out_features=num_classes),\n        )\n\n    def forward(self, x: torch.Tensor):\n        x = x.reshape((-1, 28*28))\n        return self.net(x)\n\ndef get_optimizer(model: nn.Module, config: TrainConfig):\n    if config.optimizer_type == \"sgd\":\n        return SGD(model.parameters(), lr=config.lr)\n    elif config.optimizer_type == \"adam\":\n        return Adam(model.parameters(), lr=config.lr)\n    else:\n        raise ValueError(f\"Unknown optimizer type: {config.optimizer_type}\")\n\ndef get_scheduler(optimizer: optim.Optimizer, config: TrainConfig):\n    if config.scheduler_type == \"exp\":\n        return ExponentialLR(optimizer, gamma=config.gamma)\n    elif config.scheduler_type == \"none\":\n        return None\n    else:\n        raise ValueError(f\"Unknown scheduler type: {config.scheduler_type}\")\n\ndef train_loop(model: nn.Module,\n               X_train: torch.Tensor,\n               y_train: torch.Tensor,\n               X_val: torch.Tensor,\n               y_val: torch.Tensor,\n               config: TrainConfig,\n               run_name: str | None = None):\n\n    wandb.init(\n        project=\"model_train_fashion_mnist\",\n        notes=\"version2\",\n        name=run_name,\n        config=config\n    )\n    optimizer = get_optimizer(model, config)\n    scheduler = get_scheduler(optimizer, config)\n    model.to(device).train()\n\n    for i in tqdm.trange(config.total_iterations):\n        optimizer.zero_grad()\n        loss = F.cross_entropy(model(X_train.to(device)), y_train.to(device))\n        loss.backward()\n        optimizer.step()\n        \n        metrics = {\"iteration\": i, \"loss_train\": loss.detach().cpu().item()}\n\n        if (i + 1) % config.eval_every == 0:\n            with torch.no_grad():\n                model.to(device).eval()\n                loss_val = F.cross_entropy(model(X_val.to(device)), y_val.to(device))\n                model.train()\n                metrics.update({\"loss_val\": loss_val.detach().cpu().item()})\n\n        if scheduler:\n            scheduler.step()\n            metrics.update({\"lr\": scheduler.get_last_lr()[0]})\n        else:\n            metrics.update({\"lr\": config.lr})\n\n        wandb.log(metrics)\n    \n    wandb.finish()\n\n# Main execution\nseed = 0\nset_seed(seed)\ntrain_dataset, test_dataset = get_datasets()\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"используем {device}\")\n\nX_train = train_dataset.data.float().to(device)\ny_train = train_dataset.targets.to(device)\nX_test = test_dataset.data.float().to(device)\ny_test = test_dataset.targets.to(device)\n\nnum_classes = y_train[0].item() + 1\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:57:58.510725Z","iopub.execute_input":"2025-01-06T06:57:58.511034Z","iopub.status.idle":"2025-01-06T06:57:58.758860Z","shell.execute_reply.started":"2025-01-06T06:57:58.511011Z","shell.execute_reply":"2025-01-06T06:57:58.757895Z"}},"outputs":[{"name":"stdout","text":"используем cuda\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"config = TrainConfig(eval_every=20, lr=2, total_iterations=3000, scheduler_type=\"exp\", model_type=\"batch_norm\", optimizer_type=\"sgd\")\nmodel = GenericModel(num_classes=num_classes, model_type=config.model_type)\ntrain_loop(model, X_train, y_train, X_test, y_test, config=config, run_name=f\"base_model_classification\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:58:02.833321Z","iopub.execute_input":"2025-01-06T06:58:02.833624Z","iopub.status.idle":"2025-01-06T07:00:00.521200Z","shell.execute_reply.started":"2025-01-06T06:58:02.833602Z","shell.execute_reply":"2025-01-06T07:00:00.520518Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250106_065802-hg3g1jb1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rncomp/model_train_fashion_mnist/runs/hg3g1jb1' target=\"_blank\">base_model_classification</a></strong> to <a href='https://wandb.ai/rncomp/model_train_fashion_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rncomp/model_train_fashion_mnist' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rncomp/model_train_fashion_mnist/runs/hg3g1jb1' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist/runs/hg3g1jb1</a>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 3000/3000 [01:50<00:00, 27.17it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>loss_train</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▂▂▁▂▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>lr</td><td>█▇▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>2999</td></tr><tr><td>loss_train</td><td>0.30629</td></tr><tr><td>loss_val</td><td>0.65665</td></tr><tr><td>lr</td><td>0.0</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">base_model_classification</strong> at: <a href='https://wandb.ai/rncomp/model_train_fashion_mnist/runs/hg3g1jb1' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist/runs/hg3g1jb1</a><br> View project at: <a href='https://wandb.ai/rncomp/model_train_fashion_mnist' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250106_065802-hg3g1jb1/logs</code>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"calculate_accuracy(model(X_test.to(device)), y_test.to(device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:00:00.522335Z","iopub.execute_input":"2025-01-06T07:00:00.522572Z","iopub.status.idle":"2025-01-06T07:00:00.529113Z","shell.execute_reply.started":"2025-01-06T07:00:00.522552Z","shell.execute_reply":"2025-01-06T07:00:00.528243Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"0.8702999949455261"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"config = TrainConfig(eval_every=20, lr = 2, total_iterations=3000, scheduler_type=\"none\", model_type=\"batch_norm\", optimizer_type=\"sgd\")\nmodel = GenericModel(num_classes=num_classes, model_type=config.model_type)\ntrain_loop(model, X_train, y_train, X_test, y_test, config=config, run_name=f\"base_model_classification\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:00:00.530679Z","iopub.execute_input":"2025-01-06T07:00:00.530959Z","iopub.status.idle":"2025-01-06T07:02:00.288004Z","shell.execute_reply.started":"2025-01-06T07:00:00.530939Z","shell.execute_reply":"2025-01-06T07:02:00.287313Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250106_070000-4dm1pibh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rncomp/model_train_fashion_mnist/runs/4dm1pibh' target=\"_blank\">base_model_classification</a></strong> to <a href='https://wandb.ai/rncomp/model_train_fashion_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rncomp/model_train_fashion_mnist' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rncomp/model_train_fashion_mnist/runs/4dm1pibh' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist/runs/4dm1pibh</a>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 3000/3000 [01:52<00:00, 26.65it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>loss_train</td><td>██▆▅▆▅▇▄▄▃▃▃▃▃▂▃▃▄▃▃▆▂▂▃▂▂▁▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>▁▁▄▅▅▄▅▅▅▅▅▄█▅▆▆▅▄▅▅▅▅▅▄▄▅▅▅▅▅▄▇▆▅▅▅▅▄▆▅</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>2999</td></tr><tr><td>loss_train</td><td>0.17259</td></tr><tr><td>loss_val</td><td>1.27039</td></tr><tr><td>lr</td><td>2</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">base_model_classification</strong> at: <a href='https://wandb.ai/rncomp/model_train_fashion_mnist/runs/4dm1pibh' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist/runs/4dm1pibh</a><br> View project at: <a href='https://wandb.ai/rncomp/model_train_fashion_mnist' target=\"_blank\">https://wandb.ai/rncomp/model_train_fashion_mnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250106_070000-4dm1pibh/logs</code>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"calculate_accuracy(model(X_test.to(device)), y_test.to(device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:02:00.288911Z","iopub.execute_input":"2025-01-06T07:02:00.289195Z","iopub.status.idle":"2025-01-06T07:02:00.295689Z","shell.execute_reply.started":"2025-01-06T07:02:00.289172Z","shell.execute_reply":"2025-01-06T07:02:00.294870Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.8725999593734741"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}